<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://seanhoward.me/feed.xml" rel="self" type="application/atom+xml"/><link href="https://seanhoward.me/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-10-09T03:18:45+00:00</updated><id>https://seanhoward.me/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">DuckDB - Bringing Big Data To Your Laptop</title><link href="https://seanhoward.me/blog/2023/DuckDB/" rel="alternate" type="text/html" title="DuckDB - Bringing Big Data To Your Laptop"/><published>2023-10-08T08:00:00+00:00</published><updated>2023-10-08T08:00:00+00:00</updated><id>https://seanhoward.me/blog/2023/DuckDB</id><content type="html" xml:base="https://seanhoward.me/blog/2023/DuckDB/"><![CDATA[<h3 id="table-of-contents">Table of Contents</h3> <ol> <li><a href="#exploring-duckdb---tons-of-taxis">Exploring DuckDB</a></li> <li><a href="#getting-the-data">The Data</a></li> <li><a href="#duckdb-queries">DuckDB Queries</a></li> <li><a href="#final-thoughts">Final Thoughts</a></li> <li><a href="#duckdb-performance">DuckDB Performance</a></li> </ol> <p><strong>TL;DR</strong>: <a href="https://duckdb.org/">DuckDB</a> is <a href="https://aws.amazon.com/what-is/olap/">online analytical processing (OLAP)</a> database management system with a <a href="https://duckdb.org/docs/archive/0.9.0/api/python/overview">python library</a> providing the ability to quickly perform initial <strong>E</strong>xtract <strong>T</strong>ransform <strong>L</strong>oad (<a href="https://en.wikipedia.org/wiki/Extract,_transform,_load"><strong>ETL</strong></a>) steps on larger than memory datasets without having to resort to heavier solutions like Hadoop/Spark. It’s a useful tool to extend analysis typically performed in pandas to larger collections of data, especially in parquet format.</p> <h2 id="exploring-duckdb---tons-of-taxis">Exploring DuckDB - Tons of Taxis</h2> <p>This post documents an exploratory analysis of the DuckDB python library to process big data (roughly defined as data which is too large to fit into memory). The candidate <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">dataset</a> used is the great info on taxi trips provided by the New York City Taxi and Limousine Commission. The data is in <a href="https://parquet.apache.org/">parquet</a> format, which is an open source column based format <a href="https://www.databricks.com/glossary/what-is-parquet">“designed for efficent data storage and retrieval”</a>.</p> <p>In this exploration, I look at the evolution of fare and payment type for NYC yellow taxis from 2009 to present day using DuckDB. While the results are not too surprising (fares are more expensive, more people use credit cards than cash now, and total number of yellow taxis rides is on the decline), I came away very impressed with the performance of DuckDB queries and the usefulness of its python package.</p> <details> <summary> Import DuckDB and other python libraries </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">duckdb</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">PercentFormatter</span>
<span class="kn">import</span> <span class="n">matplotlib.pylab</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span> <span class="n">urllib</span>
<span class="kn">import</span> <span class="n">os.path</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div> </div> </details> <p><br/></p> <h2 id="getting-the-data">Getting the Data</h2> <p>Data from <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page</a> is provided on a monthly basis all the way back to 2009. Investigating the url’s from the website, we can see that they follow the format <code class="language-plaintext highlighter-rouge">https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_&lt;YYYY&gt;-&lt;MM&gt;.parquet</code>, where <code class="language-plaintext highlighter-rouge">&lt;YYYY&gt;</code> is the year (e.g. <code class="language-plaintext highlighter-rouge">2021</code>) and <code class="language-plaintext highlighter-rouge">&lt;MM&gt;</code> is the month (e.g. <code class="language-plaintext highlighter-rouge">02</code> for February). So first let’s make a pandas dataframe which stores the appropriate link, month, and year.</p> <h4 id="create-dataframe-relate-links-to-monthsyears">Create dataframe relate links to months/years</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Utilize the % operator for sprintf like formatting
</span><span class="n">BASE_URL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_%d-%02d.parquet</span><span class="sh">"</span>
<span class="n">taxi_years</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">2009</span><span class="p">,</span><span class="mi">2024</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">months_as_nums</span> <span class="o">=</span>  <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">taxi_links</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="n">taxi_years</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">month</span> <span class="ow">in</span> <span class="n">months_as_nums</span><span class="p">:</span>
        <span class="n">taxi_links</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">:</span><span class="n">year</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">month</span><span class="sh">'</span><span class="p">:</span><span class="n">month</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">data_url</span><span class="sh">'</span><span class="p">:</span><span class="n">BASE_URL</span> <span class="o">%</span> <span class="p">(</span><span class="n">year</span><span class="p">,</span><span class="n">month</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="p">)</span>

<span class="n">taxi_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="nf">from_records</span><span class="p">(</span><span class="n">taxi_links</span><span class="p">)</span>

<span class="c1">#Remove months that aren't available online/haven't happened yet
</span><span class="n">taxi_df</span> <span class="o">=</span> <span class="n">taxi_df</span><span class="p">[</span><span class="o">~</span><span class="p">((</span><span class="n">taxi_df</span><span class="p">[</span><span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="mi">2023</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">taxi_df</span><span class="p">[</span><span class="sh">'</span><span class="s">month</span><span class="sh">'</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">7</span><span class="p">))]</span> 
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">taxi_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>year</th> <th>month</th> <th>data_url</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>2009</td> <td>1</td> <td>https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet</td> </tr> <tr> <th>1</th> <td>2009</td> <td>2</td> <td>https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet</td> </tr> <tr> <th>2</th> <td>2009</td> <td>3</td> <td>https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet</td> </tr> <tr> <th>3</th> <td>2009</td> <td>4</td> <td>https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet</td> </tr> <tr> <th>4</th> <td>2009</td> <td>5</td> <td>https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet</td> </tr> </tbody> </table> </div> <p><br/></p> <h4 id="downloading-the-data">Downloading the Data</h4> <details> <summary> Here's the code to download the data to the local folder. Local paths are added to taxi_df dataframe in the filename column. </summary> <p><br/> Next step is to download the data using the <code class="language-plaintext highlighter-rouge">urllib</code> package. Th below code downloads the data to the current folder with the same naming convention as provided by the NYC Taxi &amp; Limousine Commision.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">taxi_df</span><span class="p">.</span><span class="n">data_url</span><span class="p">:</span>
    <span class="c1">#check to see if file is downloaded in-case rerunning script
</span>    <span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">isfile</span><span class="p">(</span><span class="n">url</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">/</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">urllib</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="nf">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">url</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">/</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div> </div> <p>The local files can also be added to pandas dataframe used to track the urls.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">taxi_df</span><span class="p">[</span><span class="sh">'</span><span class="s">filename</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">url</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">/</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">taxi_df</span><span class="p">.</span><span class="n">data_url</span><span class="p">]</span>
</code></pre></div> </div> </details> <p><br/></p> <p>Once the data is downloaded, we can check the total size of the dataset by accessing the parquet metadata, <a href="https://duckdb.org/docs/data/parquet/metadata">more info available here</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total_size_GB</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT SUM(total_compressed_size)/(1024*1024*1024) FROM parquet_metadata(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">total_size_uncompressed_GB</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT SUM(total_uncompressed_size)/(1024*1024*1024) FROM parquet_metadata(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Total size of all files (compressed size): </span><span class="se">\t</span><span class="s"> </span><span class="si">{</span><span class="n">total_size_GB</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> GB</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Total uncompressed size (pandas in memory): </span><span class="se">\t</span><span class="s"> </span><span class="si">{</span><span class="n">total_size_uncompressed_GB</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> GB</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total size of all files (compressed size): 	 27.99 GB
Total uncompressed size (pandas in memory): 	 59.40 GB
</code></pre></div></div> <p>With a total size of all files about 28 GB, this dataset is too large to store in memory (at least on my personal computer). Especially since the uncompressed size is over twice that size at 59.4 GB. It also highlights that parquet is a compressed data format, which can save disk space for columns with many repeating or empty values.</p> <h2 id="investigate-columns---whats-the-data">Investigate Columns - What’s The Data?</h2> <p>With the data downloaded, let’s take look at the schema and see if it is consistent across all of the parquet files. If the schema does differ, DuckDB provides the ability to handling unions, with either <code class="language-plaintext highlighter-rouge">union_by_name</code> or <code class="language-plaintext highlighter-rouge">union_by_position</code> (see more <a href="https://duckdb.org/docs/data/multiple_files/combining_schemas.html#:~:text=DuckDB%20offers%20two%20ways%20of,files%20have%20the%20same%20schema.">here</a>).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">col_vals</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT file_name, path_in_schema FROM parquet_metadata(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">df</span><span class="p">()</span>
</code></pre></div></div> <p>We can see which columns are available in each dataset. Let’s group by case insensitive column names, since SQL column variables are case insensitive.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grouped_col_names</span> <span class="o">=</span> <span class="n">col_vals</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">col_vals</span><span class="p">[</span><span class="sh">'</span><span class="s">path_in_schema</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">lower</span><span class="p">())</span>\
                            <span class="p">.</span><span class="nf">agg</span><span class="p">([</span><span class="sh">'</span><span class="s">unique</span><span class="sh">'</span><span class="p">])</span>\
                            <span class="p">.</span><span class="nf">reset_index</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grouped_col_names</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead tr th{text-align:left}</style> <table border="1" class="dataframe"> <thead> <tr> <th></th> <th>path_in_schema</th> <th>file_name</th> <th>path_in_schema</th> </tr> <tr> <th></th> <th></th> <th>unique</th> <th>unique</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>__index_level_0__</td> <td>[yellow_tripdata_2010-02.parquet, yellow_tripd...</td> <td>[__index_level_0__]</td> </tr> <tr> <th>1</th> <td>airport_fee</td> <td>[yellow_tripdata_2011-01.parquet, yellow_tripd...</td> <td>[airport_fee, Airport_fee]</td> </tr> <tr> <th>2</th> <td>congestion_surcharge</td> <td>[yellow_tripdata_2011-01.parquet, yellow_tripd...</td> <td>[congestion_surcharge]</td> </tr> <tr> <th>3</th> <td>dolocationid</td> <td>[yellow_tripdata_2011-01.parquet, yellow_tripd...</td> <td>[DOLocationID]</td> </tr> <tr> <th>4</th> <td>dropoff_datetime</td> <td>[yellow_tripdata_2010-01.parquet, yellow_tripd...</td> <td>[dropoff_datetime]</td> </tr> </tbody> </table> </div> <p><br/></p> <p>And we can find the coverage of variable names across datasets by checking which files each column appears in.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">all_files</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">coverage</span> <span class="o">=</span>  <span class="p">[</span>
    <span class="nf">len</span><span class="p">(</span>
        <span class="n">all_files</span><span class="p">.</span><span class="nf">intersection</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">grouped_col_names</span><span class="p">[</span><span class="sh">'</span><span class="s">file_name</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">unique</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="p">)</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">all_files</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">grouped_col_names</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="p">]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grouped_col_names</span><span class="p">[</span><span class="sh">'</span><span class="s">coverage</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">coverage</span>
</code></pre></div></div> <p>We can see columns that appear in the largest fraction of parquet files.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grouped_col_names</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">coverage</span><span class="sh">'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead tr th{text-align:left}</style> <table border="1" class="dataframe"> <thead> <tr> <th></th> <th>path_in_schema</th> <th>file_name</th> <th>path_in_schema</th> <th>coverage</th> </tr> <tr> <th></th> <th></th> <th>unique</th> <th>unique</th> <th></th> </tr> </thead> <tbody> <tr> <th>35</th> <td>trip_distance</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[Trip_Distance, trip_distance]</td> <td>1.000000</td> </tr> <tr> <th>15</th> <td>payment_type</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[Payment_Type, payment_type]</td> <td>1.000000</td> </tr> <tr> <th>14</th> <td>passenger_count</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[Passenger_Count, passenger_count]</td> <td>1.000000</td> </tr> <tr> <th>13</th> <td>mta_tax</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[mta_tax]</td> <td>1.000000</td> </tr> <tr> <th>10</th> <td>fare_amount</td> <td>[yellow_tripdata_2010-01.parquet, yellow_tripd...</td> <td>[fare_amount]</td> <td>0.931429</td> </tr> <tr> <th>27</th> <td>tip_amount</td> <td>[yellow_tripdata_2010-01.parquet, yellow_tripd...</td> <td>[tip_amount]</td> <td>0.931429</td> </tr> <tr> <th>25</th> <td>store_and_fwd_flag</td> <td>[yellow_tripdata_2010-01.parquet, yellow_tripd...</td> <td>[store_and_fwd_flag]</td> <td>0.931429</td> </tr> <tr> <th>31</th> <td>total_amount</td> <td>[yellow_tripdata_2010-01.parquet, yellow_tripd...</td> <td>[total_amount]</td> <td>0.931429</td> </tr> <tr> <th>29</th> <td>tolls_amount</td> <td>[yellow_tripdata_2010-01.parquet, yellow_tripd...</td> <td>[tolls_amount]</td> <td>0.931429</td> </tr> <tr> <th>21</th> <td>ratecodeid</td> <td>[yellow_tripdata_2011-01.parquet, yellow_tripd...</td> <td>[RatecodeID]</td> <td>0.862857</td> </tr> </tbody> </table> </div> <p>And those appearing the smallest fraction of parquet files.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grouped_col_names</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">coverage</span><span class="sh">'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead tr th{text-align:left}</style> <table border="1" class="dataframe"> <thead> <tr> <th></th> <th>path_in_schema</th> <th>file_name</th> <th>path_in_schema</th> <th>coverage</th> </tr> <tr> <th></th> <th></th> <th>unique</th> <th>unique</th> <th></th> </tr> </thead> <tbody> <tr> <th>7</th> <td>end_lat</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[End_Lat]</td> <td>0.068571</td> </tr> <tr> <th>30</th> <td>tolls_amt</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[Tolls_Amt]</td> <td>0.068571</td> </tr> <tr> <th>8</th> <td>end_lon</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[End_Lon]</td> <td>0.068571</td> </tr> <tr> <th>28</th> <td>tip_amt</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[Tip_Amt]</td> <td>0.068571</td> </tr> <tr> <th>11</th> <td>fare_amt</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[Fare_Amt]</td> <td>0.068571</td> </tr> <tr> <th>16</th> <td>pickup_datetime</td> <td>[yellow_tripdata_2010-01.parquet, yellow_tripd...</td> <td>[pickup_datetime]</td> <td>0.068571</td> </tr> <tr> <th>17</th> <td>pickup_latitude</td> <td>[yellow_tripdata_2010-01.parquet, yellow_tripd...</td> <td>[pickup_latitude]</td> <td>0.068571</td> </tr> <tr> <th>24</th> <td>store_and_forward</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[store_and_forward]</td> <td>0.068571</td> </tr> <tr> <th>23</th> <td>start_lon</td> <td>[yellow_tripdata_2009-01.parquet, yellow_tripd...</td> <td>[Start_Lon]</td> <td>0.068571</td> </tr> <tr> <th>0</th> <td>__index_level_0__</td> <td>[yellow_tripdata_2010-02.parquet, yellow_tripd...</td> <td>[__index_level_0__]</td> <td>0.011429</td> </tr> </tbody> </table> </div> <p>For reference the most recent documentation of the schema is provided by the NYC Taxi and Limousine Comission <a href="https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf">here</a>, but it is obvious from the above investigation that this schema has changed over time.</p> <h2 id="duckdb-queries">DuckDB Queries</h2> <p>Up until now I’ve been dealing with the metadata of parquet files, which can be read into memory without reading in the entire parquet file. So the following demonstrations are the first which would be difficult to perform with this large of a dataset on a single machine without a streaming approach.</p> <h4 id="number-of-entries">Number of entries</h4> <p>First we can do a quick count of how many rows we have in all of our parquet files</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total_rows</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Total number of rows </span><span class="si">{</span><span class="n">total_rows</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total number of rows 1.72e+09
</code></pre></div></div> <p>So we have over one billion records of taxi trips over the past 14 years. That’s a lot of taxi rides!</p> <h4 id="aggregation-methods">Aggregation Methods</h4> <p>Next let’s get percentiles on the <code class="language-plaintext highlighter-rouge">total_amount</code> field. DuckDB has a collection of <a href="https://duckdb.org/docs/sql/aggregates.html">aggregation functions</a> which perform calculations in parallel <strong>as the data is scanned</strong>, which does not require loading the full dataset into memory. We’ll start off with the <code class="language-plaintext highlighter-rouge">approx_quantile</code> method, which calculates quantiles using the new <a href="https://github.com/tdunning/t-digest">T-Digest</a> method.</p> <p>Since <code class="language-plaintext highlighter-rouge">total_amount</code> is not present in all parquet files, we need to pass the <code class="language-plaintext highlighter-rouge">union_by_name=true</code> to the <code class="language-plaintext highlighter-rouge">read_parquet</code> method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># disable so it doesn't show up in markdown after nbconvert
</span><span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sh">"</span><span class="s">PRAGMA disable_progress_bar;</span><span class="sh">"</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">percentiles</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.99</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="mi">99</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total_amount_pctiles</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT approx_quantile(total_amount,[</span><span class="si">{</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="nf">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">percentiles</span><span class="p">])</span><span class="si">}</span><span class="s">]) 
FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
WHERE total_amount &gt; 0
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <details> <summary> Plot distribution of ride costs over entire dataset </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">total_amount_pctiles</span><span class="p">,</span><span class="n">percentiles</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Ride Cost (Dollars)</span><span class="sh">'</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Percentile</span><span class="sh">'</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_major_formatter</span><span class="p">(</span><span class="nc">PercentFormatter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Ride Cost For Yellow Taxi over 2009-2023</span><span class="sh">'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div> </div> </details> <p><br/></p> <figure> <img src="/assets/img/blogs/DuckDB/duckdb_taxi_36_0.png" width="80%"/> </figure> <h4 id="view-evolution-of-ride-cost-on-a-per-year-basis">View evolution of ride cost on a per year basis</h4> <p>With that out of the way, we can use the year information in the filename to plot the evolution of the cost of ride cost over the years</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pcts_over_years</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2010</span><span class="p">,</span><span class="mi">2024</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">year_fnames</span> <span class="o">=</span> <span class="n">taxi_df</span><span class="p">[</span><span class="n">taxi_df</span><span class="p">[</span><span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">year</span><span class="p">][</span><span class="sh">'</span><span class="s">filename</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">year_pcts</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
    SELECT approx_quantile(total_amount,[</span><span class="si">{</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="nf">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">percentiles</span><span class="p">])</span><span class="si">}</span><span class="s">]) 
    FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">year_fnames</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
    WHERE total_amount &gt; 0</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">year_dict</span> <span class="o">=</span> <span class="p">{</span> <span class="nf">str</span><span class="p">(</span><span class="n">year</span><span class="p">):</span><span class="n">year_pcts</span> <span class="p">}</span>
    <span class="n">pcts_over_years</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="n">pcts_over_years</span><span class="p">,</span> <span class="o">**</span><span class="n">year_dict</span><span class="p">)</span>
</code></pre></div></div> <details> <summary> Plot total fare distribution per year </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">colors</span> <span class="o">=</span> <span class="n">pl</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="nf">magma</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(.</span><span class="mi">1</span><span class="p">,.</span><span class="mi">7</span><span class="p">,</span><span class="nf">len</span><span class="p">(</span><span class="n">pcts_over_years</span><span class="p">.</span><span class="nf">keys</span><span class="p">())))</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">year</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">pcts_over_years</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">pcts_over_years</span><span class="p">[</span><span class="n">year</span><span class="p">],</span><span class="n">percentiles</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">year</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Yellow Taxi Ride Cost Distribution 2010-2023</span><span class="sh">'</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Ride Cost (Dollars)</span><span class="sh">'</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Percentile</span><span class="sh">'</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_major_formatter</span><span class="p">(</span><span class="nc">PercentFormatter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div> </div> </details> <p><br/></p> <figure> <img src="/assets/img/blogs/DuckDB/duckdb_taxi_39_0.png" width="80%"/> </figure> <p>The above plot shows that the nominal cost of yellow taxi rides in NYC has steadily rising, but has increased significantly in the year 2023. This fits with the trend of higher inflation over the past couple years. If we wanted to investigate the breakdown of the total fare over time (taxes, tips, fees, etc.), those columns are in the dataset as well.</p> <h4 id="payment-types">Payment Types</h4> <p>Now let’s look at the counts of different payment types</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">payment_type_counts</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT payment_type, COUNT(*) as occurrence_count
FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
GROUP BY payment_type; </span><span class="sh">"""</span><span class="p">).</span><span class="nf">df</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">payment_type_counts</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">occurrence_count</span><span class="sh">'</span><span class="p">],</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Payment_Type</th> <th>occurrence_count</th> </tr> </thead> <tbody> <tr> <th>5</th> <td>1</td> <td>821291745</td> </tr> <tr> <th>18</th> <td>2</td> <td>548052362</td> </tr> <tr> <th>20</th> <td>CASH</td> <td>69117503</td> </tr> <tr> <th>17</th> <td>Cash</td> <td>56282593</td> </tr> <tr> <th>6</th> <td>CSH</td> <td>50210641</td> </tr> <tr> <th>3</th> <td>Credit</td> <td>42561382</td> </tr> <tr> <th>12</th> <td>CRD</td> <td>30829647</td> </tr> <tr> <th>4</th> <td>CAS</td> <td>30792977</td> </tr> <tr> <th>16</th> <td>Cre</td> <td>27416855</td> </tr> <tr> <th>2</th> <td>Cas</td> <td>26058725</td> </tr> <tr> <th>19</th> <td>0</td> <td>4773430</td> </tr> <tr> <th>13</th> <td>3</td> <td>4440736</td> </tr> <tr> <th>0</th> <td>CRE</td> <td>3370093</td> </tr> <tr> <th>10</th> <td>CREDIT</td> <td>2330599</td> </tr> <tr> <th>1</th> <td>4</td> <td>1949962</td> </tr> <tr> <th>14</th> <td>5</td> <td>753370</td> </tr> <tr> <th>9</th> <td>No Charge</td> <td>509194</td> </tr> <tr> <th>22</th> <td>No</td> <td>200505</td> </tr> <tr> <th>11</th> <td>Dispute</td> <td>94784</td> </tr> <tr> <th>8</th> <td>Dis</td> <td>43614</td> </tr> <tr> <th>21</th> <td>NA</td> <td>40013</td> </tr> <tr> <th>15</th> <td>NOC</td> <td>31817</td> </tr> <tr> <th>7</th> <td>DIS</td> <td>6275</td> </tr> </tbody> </table> </div> <p><br/></p> <p>Like any real dataset, we have some messy data which is the result of human error and changing schemas. Looking at the official documentation, there are currently only six types of payment types with a numerical code for each:</p> <ul> <li>1 = Credit</li> <li>2 = Cash</li> <li>3 = No Charge</li> <li>4 = Dispute</li> <li>5 = Unknown</li> <li>6 = Voided Trip</li> </ul> <p>I’m interested in the trends of cash versus credit over time. Let’s hand clean this mess by matching the data to its intended value.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total_cash</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
WHERE payment_type IN (2, </span><span class="sh">'</span><span class="s">CASH</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">Cash</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">CSH</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CAS</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Cas</span><span class="sh">'</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">total_credit</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
WHERE payment_type IN (1, </span><span class="sh">'</span><span class="s">Credit</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CRD</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Cre</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">CRE</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CREDIT</span><span class="sh">'</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
Total Cash Transactions: </span><span class="se">\t\t</span><span class="si">{</span><span class="n">total_cash</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">e</span><span class="si">}</span><span class="s">
Total Credit Transactions: </span><span class="se">\t\t</span><span class="si">{</span><span class="n">total_credit</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">e</span><span class="si">}</span><span class="s">
Fraction of Total Transactions: </span><span class="se">\t</span><span class="si">{</span><span class="p">(</span><span class="n">total_cash</span><span class="o">+</span><span class="n">total_credit</span><span class="p">)</span><span class="o">/</span><span class="n">total_rows</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="s">
</span><span class="sh">"""</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total Cash Transactions: 		7.81e+08
Total Credit Transactions: 		9.28e+08
Fraction of Total Transactions: 	0.992538
</code></pre></div></div> <p>So there are slighlty more credit tranasctions over the entire dataset than cash transactions. And predictably “Cash or Credit?” corresponding to 99.25% of all transactions. But how the proportion of cash versus credit evolve over time?</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">years</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">2010</span><span class="p">,</span><span class="mi">2024</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">cash_years</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">credit_years</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="n">years</span><span class="p">:</span>
    <span class="n">year_fnames</span> <span class="o">=</span> <span class="n">taxi_df</span><span class="p">[</span><span class="n">taxi_df</span><span class="p">[</span><span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">year</span><span class="p">][</span><span class="sh">'</span><span class="s">filename</span><span class="sh">'</span><span class="p">]</span>
    
    <span class="n">cash_years</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
        <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">year_fnames</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
        WHERE payment_type IN (2, </span><span class="sh">'</span><span class="s">CASH</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">Cash</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">CSH</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CAS</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Cas</span><span class="sh">'</span><span class="s">)
        </span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">credit_years</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
        <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">year_fnames</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
        WHERE payment_type IN (1, </span><span class="sh">'</span><span class="s">Credit</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CRD</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Cre</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">CRE</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CREDIT</span><span class="sh">'</span><span class="s">)
        </span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>    
</code></pre></div></div> <details> <summary> Plot "Cash or Credit" annually over dataset" </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Total Transaction Volume
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span><span class="n">cash_years</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Cash Transactions</span><span class="sh">'</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span><span class="n">credit_years</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Credit Transactions</span><span class="sh">'</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">cash_years</span><span class="p">,</span><span class="n">credit_years</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Total Transactions</span><span class="sh">'</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Year</span><span class="sh">'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Annual Transactions</span><span class="sh">'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">NYC Taxi Rides - Cash vs. Credit Total Volume</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div> </div> </details> <p><br/></p> <figure> <img src="/assets/img/blogs/DuckDB/duckdb_taxi_49_0.png" width="80%"/> </figure> <details> <summary> Plot "Cash or Credit" as percentage of all transactions </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Transaction Percentage
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">divide</span><span class="p">(</span><span class="n">cash_years</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">cash_years</span><span class="p">,</span><span class="n">credit_years</span><span class="p">)),</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Cash</span><span class="sh">'</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">divide</span><span class="p">(</span><span class="n">credit_years</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">cash_years</span><span class="p">,</span><span class="n">credit_years</span><span class="p">)),</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Credit</span><span class="sh">'</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Year</span><span class="sh">'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Transaction Percentage</span><span class="sh">'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">NYC Taxi Rides - Cash vs. Credit Percentage</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_major_formatter</span><span class="p">(</span><span class="nc">PercentFormatter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div> </div> </details> <p><br/></p> <figure> <img src="/assets/img/blogs/DuckDB/duckdb_taxi_50_0.png" width="80%"/> </figure> <h4 id="im-different---user-defined-functions">I’m Different - User Defined Functions</h4> <p>If the SQL queries and DuckDB aggregate functions are not enough for a given use case, DuckDB provides the ability to use User Defined Functions (UDF). With UDF’s, we can define pure python functions that are calculated <em>as the data is continously read</em>. So if the initial aggregation is still too large for memory, we can apply our own defined functions as the data is read in. It is especially cool that we can use third party libraries within the defined function! I’m assuming this works since DuckDB is bound to the particular python process being run.</p> <p>For this example, let’s do some random math where we take the absolute difference between two values and then calculate the square root with numpy. If we provide type annotation, DuckDB is smart enough to handle the rest. We just need to select columns where both values are not null so the query doesn’t error out.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">random_func</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">))</span>

<span class="n">duckdb</span><span class="p">.</span><span class="nf">create_function</span><span class="p">(</span><span class="sh">'</span><span class="s">random_func</span><span class="sh">'</span><span class="p">,</span><span class="n">random_func</span><span class="p">);</span>
</code></pre></div></div> <p>Now let’s use the function in a query by applying the function to the <code class="language-plaintext highlighter-rouge">fare_amount</code> and <code class="language-plaintext highlighter-rouge">tip_amount</code> method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">random_ans</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT AVG(random_func(fare_amount,tip_amount)) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
        WHERE tip_amount IS NOT NULL
        AND fare_amount IS NOT NULL
        </span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Average value of our random function </span><span class="si">{</span><span class="n">random_ans</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average value of our random function 3.07
</code></pre></div></div> <p>Introducing this python function did cause the query to be much slower than previous operations. Unlike other queries which quickly brought my CPU usage up to 100%, this one kept my CPU at about 20% for the entire operation. So it is worth trying to avoid python UDFs as the data size becomes large or performance is important.</p> <h2 id="final-thoughts">Final Thoughts</h2> <p>After playing around with DuckDB for a bit, I’m pretty impressed. I think it has an obvious use case for analytical workloads where the data which is larger your computer’s memory, where performance is important, and where its simplicity outweighs potential gains from more heavyweight big data analysis services. Since DuckDB deals with databases in a column based format, I also think it is a natural candidate to process parquet files.</p> <h2 id="duckdb-performance">DuckDB Performance</h2> <p>Here are timed benchmarks for all queries performed above. As a reminder, the dataset is 28 GB compressed, 59 GB uncompressed, and has 1.72 billion rows.</p> <p>These numbers will depend on hardware, so for reference I have a <a href="https://www.amd.com/en/product/8456">AMD 3600</a> CPU and the data is stored on a <a href="https://semiconductor.samsung.com/us/consumer-storage/internal-ssd/970evoplus/">Samsung 970 EVO</a> SSD which has quoted read/write times of 3500 MB/s and 3,300 MB/s respectively. Based on these speeds, I would expect loading in all columns of all parquet files into memory to take at least 28 GB / 3.5 GB/s \(\approx\) 8 seconds <em>if</em> I had that much RAM (which I don’t). Most of the default DuckDB queries which require scanning the all files are on the same time scale of around 10 seconds or less. I’m assuming DuckDB can achieve these times because it can selectively load only the parts of the dataset it needs to execute the query.</p> <h4 id="query-getting-total-compressed-size-from-parquet-metadata"><strong>Query:</strong> Getting total compressed size from parquet metadata</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT SUM(total_compressed_size)/(1024*1024*1024) FROM parquet_metadata(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>79.5 ms ± 2.51 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre></div></div> <h4 id="query-getting-total-uncompressed-size-from-parquet-metadata"><strong>Query:</strong> Getting total uncompressed size from parquet metadata</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT SUM(total_uncompressed_size)/(1024*1024*1024) FROM parquet_metadata(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>82.8 ms ± 2.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
</code></pre></div></div> <h4 id="query-getting-filename-and-column-names-from-metadata"><strong>Query:</strong> Getting filename and column names from metadata</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT file_name, path_in_schema FROM parquet_metadata(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">df</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>78 ms ± 194 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</code></pre></div></div> <h4 id="query-get-total-number-of-transactions"><strong>Query:</strong> Get total number of transactions</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>78.1 ms ± 304 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</code></pre></div></div> <h4 id="query-get-approx-percentiles-of-total-amount-column"><strong>Query:</strong> Get Approx. Percentiles of Total Amount Column</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT approx_quantile(total_amount,[</span><span class="si">{</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="nf">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">percentiles</span><span class="p">])</span><span class="si">}</span><span class="s">]) 
FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
WHERE total_amount &gt; 0
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>11.5 s ± 19.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre></div></div> <h4 id="query-get-approx-percentiles-of-total-amount-column-per-year"><strong>Query:</strong> Get Approx Percentiles of Total Amount Column Per Year</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">pcts_over_years</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2010</span><span class="p">,</span><span class="mi">2024</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">year_fnames</span> <span class="o">=</span> <span class="n">taxi_df</span><span class="p">[</span><span class="n">taxi_df</span><span class="p">[</span><span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">year</span><span class="p">][</span><span class="sh">'</span><span class="s">filename</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">year_pcts</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
    SELECT approx_quantile(total_amount,[</span><span class="si">{</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="nf">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">percentiles</span><span class="p">])</span><span class="si">}</span><span class="s">]) 
    FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">year_fnames</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
    WHERE total_amount &gt; 0</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">year_dict</span> <span class="o">=</span> <span class="p">{</span> <span class="nf">str</span><span class="p">(</span><span class="n">year</span><span class="p">):</span><span class="n">year_pcts</span> <span class="p">}</span>
    <span class="n">pcts_over_years</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="n">pcts_over_years</span><span class="p">,</span> <span class="o">**</span><span class="n">year_dict</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12.8 s ± 28.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre></div></div> <h4 id="query-get-number-of-transactions-per-payment-type"><strong>Query:</strong> Get Number of Transactions Per Payment Type</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT payment_type, COUNT(*) as occurrence_count
FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
GROUP BY payment_type; </span><span class="sh">"""</span><span class="p">).</span><span class="nf">df</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5.73 s ± 38.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre></div></div> <h4 id="query-get-number-of-cash-transactions-total"><strong>Query:</strong> Get Number of Cash Transactions Total</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">total_cash</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
WHERE payment_type IN (2, </span><span class="sh">'</span><span class="s">CASH</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">Cash</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">CSH</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CAS</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Cas</span><span class="sh">'</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>6.4 s ± 21.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre></div></div> <h4 id="query-get-number-of-credit-transactions-total"><strong>Query:</strong> Get Number of Credit Transactions Total</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
WHERE payment_type IN (1, </span><span class="sh">'</span><span class="s">Credit</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CRD</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Cre</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">CRE</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CREDIT</span><span class="sh">'</span><span class="s">)
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>  
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>6.52 s ± 27.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre></div></div> <h4 id="query-get-number-of-cashcredit-transactions-per-year"><strong>Query:</strong> Get Number of Cash/Credit Transactions Per Year</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>

<span class="n">years</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">2010</span><span class="p">,</span><span class="mi">2024</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">cash_years</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">credit_years</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="n">years</span><span class="p">:</span>
    <span class="n">year_fnames</span> <span class="o">=</span> <span class="n">taxi_df</span><span class="p">[</span><span class="n">taxi_df</span><span class="p">[</span><span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">year</span><span class="p">][</span><span class="sh">'</span><span class="s">filename</span><span class="sh">'</span><span class="p">]</span>
    
    <span class="n">cash_years</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
        <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">year_fnames</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
        WHERE payment_type IN (2, </span><span class="sh">'</span><span class="s">CASH</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">Cash</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">CSH</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CAS</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Cas</span><span class="sh">'</span><span class="s">)
        </span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">credit_years</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
        <span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT COUNT(*) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">year_fnames</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
        WHERE payment_type IN (1, </span><span class="sh">'</span><span class="s">Credit</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CRD</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">Cre</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="s">CRE</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">CREDIT</span><span class="sh">'</span><span class="s">)
        </span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>    
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>13.2 s ± 49.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre></div></div> <h4 id="query-user-defined-function"><strong>Query:</strong> User Defined Function</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Got impatient since this is a really slow query
</span><span class="kn">from</span> <span class="n">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>

<span class="n">start</span> <span class="o">=</span> <span class="nf">timer</span><span class="p">()</span>
<span class="n">duckdb</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT AVG(random_func(fare_amount,tip_amount)) FROM read_parquet(</span><span class="si">{</span><span class="nf">list</span><span class="p">(</span><span class="n">taxi_df</span><span class="p">.</span><span class="n">filename</span><span class="p">)</span><span class="si">}</span><span class="s">,union_by_name=true)
        WHERE tip_amount IS NOT NULL
        AND fare_amount IS NOT NULL
        </span><span class="sh">"""</span><span class="p">).</span><span class="nf">fetchall</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">end</span> <span class="o">=</span> <span class="nf">timer</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">User Defined Function Took </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">e</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User Defined Function Took 2.09e+03 seconds
</code></pre></div></div> <p>Which is about 35 minutes.</p>]]></content><author><name></name></author><category term="Intros"/><category term="Data-Science"/><summary type="html"><![CDATA[Exploring DuckDB's capability on a larger than memory parquet dataset]]></summary></entry><entry><title type="html">Accessing Google’s Petabyte Scale Satellite Data</title><link href="https://seanhoward.me/blog/2022/Google_Earth_Engine/" rel="alternate" type="text/html" title="Accessing Google’s Petabyte Scale Satellite Data"/><published>2022-09-29T16:40:16+00:00</published><updated>2022-09-29T16:40:16+00:00</updated><id>https://seanhoward.me/blog/2022/Google_Earth_Engine</id><content type="html" xml:base="https://seanhoward.me/blog/2022/Google_Earth_Engine/"><![CDATA[<h2 id="accessing-satellite-imagery-with-google-earth-engine">Accessing Satellite Imagery with Google Earth Engine</h2> <p><a href="https://colab.research.google.com/github/st-howard/blog-notebooks/blob/main/Google_Earth_Engine/Satellite%20Imagery%20with%20Google%20Earth%20Engine.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab"/></a></p> <p>Satellites provide a wealth of information about the world: monitoring human development, tracking climate change, and providing vital information at scale for disaster response. Over the past decades, the scale of publicly accessible satellite data has increased exponentially. This data is collected by many research consortia, often stored on servers and accessible with APIs unique to the mission. <a href="https://earthengine.google.com/">Google’s Earth Engine</a> hosts a large, multi-petabyte <a href="https://developers.google.com/earth-engine/datasets/">catalog</a> of satellite imagery which can be accessed and queried with a common API, for free with a Google account. This service, which requires the technical knowledge and bankroll of a tech giant, is boon for using satellite imagery at scale to learn more about the world we live in. This post documents basic interaction with the Earth Engine API in python, focusing on how to get Sentinel-2 MSI imagery.</p> <details> <summary>Load python libraries</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import Libraries
</span>
<span class="kn">import</span> <span class="n">ee</span>  <span class="c1"># Google Earth Engine
</span><span class="kn">import</span> <span class="n">eemont</span>  <span class="c1"># Extension to Google Earth Engine
</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">rasterio</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="n">geopy</span>
<span class="kn">import</span> <span class="n">geopy.distance</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div> </div> </details> <h3 id="autheticate-google-earth-engine-account">Autheticate Google Earth Engine Account</h3> <p>The first step of using Google Earth Engine (after signing up with a google account) is to authenticate your session, which can be done interactively in a jupyter notebook by running the following commands.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ee</span><span class="p">.</span><span class="nc">Authenticate</span><span class="p">()</span>
<span class="n">ee</span><span class="p">.</span><span class="nc">Initialize</span><span class="p">()</span>
</code></pre></div></div> <h3 id="select-location-to-request-imagery">Select Location to Request Imagery</h3> <p>To query satellite imagery of a particular location on earth, we first need to create a Earth Engine <a href="https://developers.google.com/earth-engine/guides/geometries">Geometry Object</a>. I’ve found the eeMont python package that extends Google Earth Engine to be helpful in exploratory analysis, since it can return a Geometry Point based on a text query. Below is a query for Washington D.C.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">point</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="n">Geometry</span><span class="p">.</span><span class="nc">PointFromQuery</span><span class="p">(</span><span class="sh">"</span><span class="s">Washington DC</span><span class="sh">"</span><span class="p">,</span> <span class="n">user_agent</span><span class="o">=</span><span class="sh">"</span><span class="s">earth_engine_example</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Which returns a single longitude, latitude pair for Washington D.C., as you would get if the same query was entered into Google Maps.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ee.Geometry({
  "functionInvocationValue": {
    "functionName": "GeometryConstructors.Point",
    "arguments": {
      "coordinates": {
        "constantValue": [
          -77.0365427,
          38.8950368
        ]
      }
    }
  }
})
</code></pre></div></div> <h3 id="create-bounding-box-helper-function">Create Bounding Box Helper Function</h3> <p>For this example, I want to get a subset of Sentinel-2 Image. In requesting an image, it is necessary to request either the scale (i.e. sampling distance of pixel) of the image or the pixel dimensions of the subset. Sentinel-2 MSI Imagery has a <a href="https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR">10m resolution</a>, however if I request a full image at that resolution it is too large. And if I request a image with a specified pixel dimension, then the image is downsampled to a worse resolution than the native 10m.</p> <p>To get an image subset with roughly native resolution, I created a function that makes a <a href="https://en.wikipedia.org/wiki/Minimum_bounding_box">bounding box</a> of a specified size centered on an initial latitude and longitude point.</p> <details> <summary>Bounding Box helper function</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">BBoxFromPoint</span><span class="p">(</span><span class="n">bbox_size</span><span class="p">,</span> <span class="n">lat_point</span><span class="p">,</span> <span class="n">lon_point</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    bbox_size - either square in km (one value) or two values in NS km, then EW km
    lat_point - lat center of bounding box
    lon_point - lon center of bounding box

    returns ee.Geometry object of bounding box
    </span><span class="sh">"""</span>
    <span class="k">if</span> <span class="nf">type</span><span class="p">(</span><span class="n">bbox_size</span><span class="p">)</span> <span class="o">==</span> <span class="nb">int</span> <span class="ow">or</span> <span class="nf">type</span><span class="p">(</span><span class="n">bbox_size</span><span class="p">)</span> <span class="o">==</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">bbox_size</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">bbox_size</span><span class="p">])</span>

    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">bbox_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">lat_km</span> <span class="o">=</span> <span class="n">bbox_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">lon_km</span> <span class="o">=</span> <span class="n">bbox_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">bbox_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">lat_km</span><span class="p">,</span> <span class="n">lon_km</span> <span class="o">=</span> <span class="n">bbox_size</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sh">"</span><span class="s">bbox_size must be either length 1 or 2</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">origin</span> <span class="o">=</span> <span class="n">geopy</span><span class="p">.</span><span class="nc">Point</span><span class="p">(</span><span class="n">lat_point</span><span class="p">,</span> <span class="n">lon_point</span><span class="p">)</span>
    <span class="n">lat_min</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">geopy</span><span class="p">.</span><span class="n">distance</span><span class="p">.</span><span class="nf">geodesic</span><span class="p">(</span><span class="n">kilometers</span><span class="o">=</span><span class="n">lat_km</span> <span class="o">/</span> <span class="mi">2</span><span class="p">).</span><span class="nf">destination</span><span class="p">(</span><span class="n">origin</span><span class="p">,</span> <span class="n">bearing</span><span class="o">=</span><span class="mi">180</span><span class="p">)</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">lat_max</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">geopy</span><span class="p">.</span><span class="n">distance</span><span class="p">.</span><span class="nf">geodesic</span><span class="p">(</span><span class="n">kilometers</span><span class="o">=</span><span class="n">lat_km</span> <span class="o">/</span> <span class="mi">2</span><span class="p">).</span><span class="nf">destination</span><span class="p">(</span><span class="n">origin</span><span class="p">,</span> <span class="n">bearing</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">lon_min</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">geopy</span><span class="p">.</span><span class="n">distance</span><span class="p">.</span><span class="nf">geodesic</span><span class="p">(</span><span class="n">kilometers</span><span class="o">=</span><span class="n">lat_km</span> <span class="o">/</span> <span class="mi">2</span><span class="p">).</span><span class="nf">destination</span><span class="p">(</span><span class="n">origin</span><span class="p">,</span> <span class="n">bearing</span><span class="o">=</span><span class="mi">270</span><span class="p">)</span>
    <span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">lon_max</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">geopy</span><span class="p">.</span><span class="n">distance</span><span class="p">.</span><span class="nf">geodesic</span><span class="p">(</span><span class="n">kilometers</span><span class="o">=</span><span class="n">lat_km</span> <span class="o">/</span> <span class="mi">2</span><span class="p">).</span><span class="nf">destination</span><span class="p">(</span><span class="n">origin</span><span class="p">,</span> <span class="n">bearing</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">ee</span><span class="p">.</span><span class="n">Geometry</span><span class="p">.</span><span class="nc">BBox</span><span class="p">(</span><span class="n">lon_min</span><span class="p">,</span> <span class="n">lat_min</span><span class="p">,</span> <span class="n">lon_max</span><span class="p">,</span> <span class="n">lat_max</span><span class="p">)</span>
</code></pre></div> </div> </details> <p><br/></p> <p>With this information, I created a bounding box of 5.12 km x 5.12 km so that when I ask for a 512 x 512 pixel image it is approximately at the native 10m resolution of Sentinel-2 MSI imagery.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_lon</span><span class="p">,</span> <span class="n">DC_lat</span> <span class="o">=</span> <span class="n">point</span><span class="p">.</span><span class="nf">coordinates</span><span class="p">().</span><span class="nf">getInfo</span><span class="p">()</span>
<span class="n">DC_bbox</span> <span class="o">=</span> <span class="nc">BBoxFromPoint</span><span class="p">(</span><span class="mf">5.12</span><span class="p">,</span> <span class="n">DC_lat</span><span class="p">,</span> <span class="n">DC_lon</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_bbox</span><span class="p">.</span><span class="nf">getInfo</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'geodesic': False,
 'type': 'Polygon',
 'coordinates': [[[-77.06605134109452, 38.87197649154135],
   [-77.00703405890545, 38.87197649154135],
   [-77.00703405890545, 38.91809701712762],
   [-77.06605134109452, 38.91809701712762],
   [-77.06605134109452, 38.87197649154135]]]}
</code></pre></div></div> <h3 id="get-image-collection-from-google-earth-engine">Get Image Collection From Google Earth Engine</h3> <p>With a location selected, the next step of getting imagery from Google Earth Engine is to specify the dataset. Below this is done by running <code class="language-plaintext highlighter-rouge">ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")</code>. Creating the <code class="language-plaintext highlighter-rouge">ImageCollection</code> object does not return the entire dataset (which is a good thing because it is extremely large), but creates a object on the user side which, when prompted by other methods, can make a request of Google’s server. This is detailed in the <a href="https://developers.google.com/earth-engine/guides/client_server">Client vs. Server</a> section of Google’s documentation.</p> <p>After creating the ImageCollection object, the data we are interested can be specified with filter functions, in this case <code class="language-plaintext highlighter-rouge">filterBounds</code> for images intersecting the Geometry object, <code class="language-plaintext highlighter-rouge">filterDate</code> for specifying the date range to look for images, and <code class="language-plaintext highlighter-rouge">filter</code> for a generic filter which can query against properties of each image, listed <a href="https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR">here</a> for Sentinel-2. The last <code class="language-plaintext highlighter-rouge">filter</code> selects images with 5% or less cloudy pixels.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_collection</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ee</span><span class="p">.</span><span class="nc">ImageCollection</span><span class="p">(</span><span class="sh">"</span><span class="s">COPERNICUS/S2_SR_HARMONIZED</span><span class="sh">"</span><span class="p">)</span>
    <span class="p">.</span><span class="nf">filterBounds</span><span class="p">(</span><span class="n">DC_bbox</span><span class="p">)</span>
    <span class="p">.</span><span class="nf">filterDate</span><span class="p">(</span><span class="sh">"</span><span class="s">2020-01-01</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">2021-01-01</span><span class="sh">"</span><span class="p">)</span>
    <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="n">ee</span><span class="p">.</span><span class="n">Filter</span><span class="p">.</span><span class="nf">lte</span><span class="p">(</span><span class="sh">"</span><span class="s">CLOUDY_PIXEL_PERCENTAGE</span><span class="sh">"</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="p">)</span>
</code></pre></div></div> <p>In the above image collection, multiple images will satisfy the geospatial, temporal, and cloud percentage requirements. Therefore, it is necessary to select a single image from the set of qualifying images. A simple way to do that is with the <code class="language-plaintext highlighter-rouge">first</code> method, which can be passed into the <code class="language-plaintext highlighter-rouge">ee.Image</code> constructor to make an image object.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_image</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="nc">Image</span><span class="p">(</span><span class="n">DC_collection</span><span class="p">.</span><span class="nf">first</span><span class="p">())</span>
</code></pre></div></div> <p>To grab the metadata associated with this image, we need to call the <code class="language-plaintext highlighter-rouge">getInfo</code> method on the Image object. This is because the Image object exists on the Client side and has not yet made a request to Google’s servers.</p> <details> <summary>Investigate details of Image metadata</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_Image_info</span> <span class="o">=</span> <span class="n">DC_image</span><span class="p">.</span><span class="nf">getInfo</span><span class="p">()</span>
</code></pre></div> </div> <p>The metadata of the image is returned as a python dictionary and contains a variety of metadata associated with the image, including the acquisition date.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Image Info is a </span><span class="sh">"</span><span class="p">,</span> <span class="nf">type</span><span class="p">(</span><span class="n">DC_Image_info</span><span class="p">))</span>
</code></pre></div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Image Info is a  &lt;class 'dict'&gt;
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Fields of Image Info:</span><span class="sh">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">DC_Image_info</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
</code></pre></div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fields of Image Info:
type
bands
version
id
properties
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Start time of Image:</span><span class="se">\t</span><span class="sh">"</span><span class="p">,</span> <span class="n">DC_Image_info</span><span class="p">[</span><span class="sh">"</span><span class="s">properties</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">system:time_start</span><span class="sh">"</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">Date:</span><span class="se">\t\t\t</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="nf">fromtimestamp</span><span class="p">(</span>
        <span class="n">DC_Image_info</span><span class="p">[</span><span class="sh">"</span><span class="s">properties</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">system:time_start</span><span class="sh">"</span><span class="p">]</span> <span class="o">/</span> <span class="mi">1000</span>
    <span class="p">).</span><span class="nf">strftime</span><span class="p">(</span><span class="sh">"</span><span class="s">%c</span><span class="sh">"</span><span class="p">),</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Sentinel ID:</span><span class="se">\t\t</span><span class="sh">"</span><span class="p">,</span> <span class="n">DC_Image_info</span><span class="p">[</span><span class="sh">"</span><span class="s">properties</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">DATATAKE_IDENTIFIER</span><span class="sh">"</span><span class="p">])</span>
</code></pre></div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Start time of Image:	 1579190537887
Date:			 Thu Jan 16 11:02:17 2020
Sentinel ID:		 GS2B_20200116T155609_014952_N02.13
</code></pre></div> </div> </details> <p><br/></p> <p>To get the actual image from Google’s servers, you need to call either <code class="language-plaintext highlighter-rouge">getThumbURL</code> or <code class="language-plaintext highlighter-rouge">getDownloadURL</code>. <code class="language-plaintext highlighter-rouge">getThumbURL</code> will generate a url with the image in the requested format. This function <strong>requires</strong> a dictionary specifying the parameters necessary to generate the image. For instance, Sentinel-2 data has over 10 bands and which band should be mapped to Red, Green, and Blue is ambiguous. Below the bands B4, B3, B2 are mapped red, green, and blue respectively. For multispectral imagery (MSI) these bands correspond to their mapped colors, but for other formats of imagery such as those beyond the visible must be assigned to artificial colors.</p> <p>In addition to specifying the bands, the pixel dimensions of the image, and the bounding box of the image, the data range of the image needs to be specified. According to the data description on the Google Earth Engine website, the data value of the band is the surface reflectance multiplied by 10,000. I’ve found decent results by setting the data range from $[0,4000]$, or a surface reflectance from 0% to 40%.</p> <p>The url can be read into a PIL image by using the <code class="language-plaintext highlighter-rouge">requests</code> module and passing the raw response into <code class="language-plaintext highlighter-rouge">PIL.Image.open()</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_url</span> <span class="o">=</span> <span class="n">DC_image</span><span class="p">.</span><span class="nf">getThumbURL</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">format</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">png</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">bands</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">B4</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">B3</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">B2</span><span class="sh">"</span><span class="p">],</span>
        <span class="sh">"</span><span class="s">dimensions</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span>
        <span class="sh">"</span><span class="s">region</span><span class="sh">"</span><span class="p">:</span> <span class="n">DC_bbox</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">min</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">max</span><span class="sh">"</span><span class="p">:</span> <span class="mi">4000</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_thumbURL_response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">DC_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_PIL</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">DC_thumbURL_response</span><span class="p">.</span><span class="n">raw</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_PIL</span>
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Google_Earth_Engine/gee_0.png" width="60%"/> </figure> <p>Since the data is in a PIL Image, it can be saved easily with the <code class="language-plaintext highlighter-rouge">.save</code> method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_PIL</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">Sentinel-2_DC.png</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="download-image-as-a-geotiff">Download Image as a GeoTiff</h3> <p>The thumbnails from <code class="language-plaintext highlighter-rouge">getThumbURL</code> are meant to be visualized and therefore require either one band (grayscale) or three bands (RGB). However, to get the full data from all or a selection of the bands collected you need to download the GeoTiff with <code class="language-plaintext highlighter-rouge">getDownloadURL</code>. The format is very similar to the <code class="language-plaintext highlighter-rouge">getThumbURL</code> method as it requires a dictionary specifying parameters of image. Instead of generating a png, the download url is a zip file which unzips into a GeoTiff.</p> <p>The code below generates the download url, downloads the image, uzips it, loads it with rasterio, and plots the image (same as above) and the histogram of the reflectance values</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_downloadURL</span> <span class="o">=</span> <span class="n">DC_image</span><span class="p">.</span><span class="nf">getDownloadURL</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">bands</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">B2</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">B3</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">B4</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">B8</span><span class="sh">"</span><span class="p">],</span>
        <span class="sh">"</span><span class="s">dimensions</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span>
        <span class="sh">"</span><span class="s">region</span><span class="sh">"</span><span class="p">:</span> <span class="n">DC_bbox</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">filePerBand</span><span class="sh">"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div> <details> <summary>Download Image as Tiff and Plot Image</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_download_response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">DC_downloadURL</span><span class="p">)</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">DC_geotiff.zip</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
    <span class="n">fd</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">DC_download_response</span><span class="p">.</span><span class="n">content</span><span class="p">)</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">zipfile</span>

<span class="k">with</span> <span class="n">zipfile</span><span class="p">.</span><span class="nc">ZipFile</span><span class="p">(</span><span class="sh">"</span><span class="s">DC_geotiff.zip</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="p">.</span><span class="nf">extractall</span><span class="p">()</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">glob</span>

<span class="n">fname</span> <span class="o">=</span> <span class="n">glob</span><span class="p">.</span><span class="nf">glob</span><span class="p">(</span><span class="sh">"</span><span class="s">*.tif</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_dataset</span> <span class="o">=</span> <span class="n">rasterio</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">fname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Image heigt, width:</span><span class="sh">"</span><span class="p">,</span> <span class="n">DC_dataset</span><span class="p">.</span><span class="n">height</span><span class="p">,</span> <span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">,</span> <span class="n">DC_dataset</span><span class="p">.</span><span class="n">width</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Number Bands:</span><span class="sh">"</span><span class="p">,</span> <span class="n">DC_dataset</span><span class="p">.</span><span class="n">count</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Datatype:</span><span class="sh">"</span><span class="p">,</span> <span class="n">DC_dataset</span><span class="p">.</span><span class="n">dtypes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Image heigt, width: 512 , 512
Number Bands: 4
Datatype: uint16
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DC_raster</span> <span class="o">=</span> <span class="n">DC_dataset</span><span class="p">.</span><span class="nf">read</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre></div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">moveaxis</span><span class="p">(</span><span class="n">DC_raster</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">DC_raster</span><span class="p">,</span> <span class="mi">99</span><span class="p">))</span>
</code></pre></div> </div> </details> <p><br/></p> <figure> <img src="/assets/img/blogs/Google_Earth_Engine/gee_1.png" width="60%"/> <figcaption> GeoTiff image plotted with rasterio </figcaption> </figure> <p>And with the full range of the bands, which are processed to be in units of surface reflectance multiplied by 10,000, the histogram of the selected bands can be plotted. Notably, the GeoTiff bands have a much larger dynamic range (16-bit) versus the png image returned from <code class="language-plaintext highlighter-rouge">getThumbUrL</code> (8-bit).</p> <details> <summary>Plot histogram of B2, B3, B4, B8</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Red band
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span>
    <span class="p">(</span><span class="n">DC_dataset</span><span class="p">.</span><span class="nf">read</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">flatten</span><span class="p">())</span> <span class="o">/</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">B4-Red</span><span class="sh">"</span>
<span class="p">)</span>

<span class="c1"># Blue band
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span>
    <span class="p">(</span><span class="n">DC_dataset</span><span class="p">.</span><span class="nf">read</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">flatten</span><span class="p">())</span> <span class="o">/</span> <span class="mi">10000</span><span class="p">,</span>
    <span class="mi">200</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">green</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">B3-Green</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Green band
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span>
    <span class="p">(</span><span class="n">DC_dataset</span><span class="p">.</span><span class="nf">read</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">flatten</span><span class="p">())</span> <span class="o">/</span> <span class="mi">10000</span><span class="p">,</span>
    <span class="mi">200</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">B2-Blue</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># NIR band
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span>
    <span class="p">(</span><span class="n">DC_dataset</span><span class="p">.</span><span class="nf">read</span><span class="p">(</span><span class="mi">4</span><span class="p">).</span><span class="nf">flatten</span><span class="p">())</span> <span class="o">/</span> <span class="mi">10000</span><span class="p">,</span>
    <span class="mi">200</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">B8-NIR</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">xscale</span><span class="p">(</span><span class="sh">"</span><span class="s">log</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Surface Reflectance</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Surface Reflectance Values for D.C. Sentinel-2 Image</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div> </div> </details> <p><br/></p> <figure> <img src="/assets/img/blogs/Google_Earth_Engine/gee_2.png" width="60%"/> <figcaption> GeoTiff image plotted with rasterio </figcaption> </figure> <h3 id="generate-timelapse-video">Generate timelapse video</h3> <p>As an example of the power and flexibility of Google Earth Engine, here is a quick script to save frames for a timelapse video of the construction of <a href="https://en.wikipedia.org/wiki/Fiery_Cross_Reef">Fiery Cross Reef</a>, a coral reef in the South China Sea which was <a href="https://www.cnbc.com/2017/06/30/china-builds-military-facilities-south-china-sea-islands.html">terraformed by China into a naval base</a> from 2013 to 2017.</p> <details> <summary>Generate movie of Fiery Cross Reef construciton</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fcr_bbox</span> <span class="o">=</span> <span class="nc">BBoxFromPoint</span><span class="p">(</span><span class="mf">0.03</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="mf">9.549167</span><span class="p">,</span> <span class="mf">112.889167</span><span class="p">)</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fcr_collection</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ee</span><span class="p">.</span><span class="nc">ImageCollection</span><span class="p">(</span><span class="sh">"</span><span class="s">LANDSAT/LC08/C02/T1_L2</span><span class="sh">"</span><span class="p">)</span>
    <span class="p">.</span><span class="nf">filterBounds</span><span class="p">(</span><span class="n">fcr_bbox</span><span class="p">)</span>
    <span class="p">.</span><span class="nf">filterDate</span><span class="p">(</span><span class="sh">"</span><span class="s">2013-04-01</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">2018-06-01</span><span class="sh">"</span><span class="p">)</span>
    <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="n">ee</span><span class="p">.</span><span class="n">Filter</span><span class="p">.</span><span class="nf">lte</span><span class="p">(</span><span class="sh">"</span><span class="s">CLOUD_COVER</span><span class="sh">"</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
<span class="p">)</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test the example image
</span>
<span class="n">fcr_first_image</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="nc">Image</span><span class="p">(</span><span class="n">fcr_collection</span><span class="p">.</span><span class="nf">first</span><span class="p">())</span>

<span class="n">fcr_url</span> <span class="o">=</span> <span class="n">fcr_first_image</span><span class="p">.</span><span class="nf">getThumbURL</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">format</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">png</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">bands</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">SR_B4</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SR_B3</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SR_B2</span><span class="sh">"</span><span class="p">],</span>
        <span class="sh">"</span><span class="s">dimensions</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span>
        <span class="sh">"</span><span class="s">region</span><span class="sh">"</span><span class="p">:</span> <span class="n">fcr_bbox</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">min</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">max</span><span class="sh">"</span><span class="p">:</span> <span class="mi">29000</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">fcr_first_response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">fcr_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">fcr_PIL</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">fcr_first_response</span><span class="p">.</span><span class="n">raw</span><span class="p">)</span>

<span class="n">fcr_PIL</span>
</code></pre></div> </div> <figure> <img src="/assets/img/blogs/Google_Earth_Engine/gee_3.png" width="60%"/> <figcaption> Fiery Cross Reef before terraforming </figcaption> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loop through the images and save them
</span>
<span class="n">number_of_images</span> <span class="o">=</span> <span class="n">fcr_collection</span><span class="p">.</span><span class="nf">size</span><span class="p">().</span><span class="nf">getInfo</span><span class="p">()</span>
<span class="n">fcr_list</span> <span class="o">=</span> <span class="n">fcr_collection</span><span class="p">.</span><span class="nf">toList</span><span class="p">(</span><span class="n">fcr_collection</span><span class="p">.</span><span class="nf">size</span><span class="p">())</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">number_of_images</span><span class="p">):</span>
    <span class="n">fcr_image</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="nc">Image</span><span class="p">(</span><span class="n">fcr_list</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

    <span class="n">fcr_url</span> <span class="o">=</span> <span class="n">fcr_image</span><span class="p">.</span><span class="nf">getThumbURL</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="sh">"</span><span class="s">format</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">png</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">bands</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">SR_B4</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SR_B3</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SR_B2</span><span class="sh">"</span><span class="p">],</span>
            <span class="sh">"</span><span class="s">dimensions</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span>
            <span class="sh">"</span><span class="s">region</span><span class="sh">"</span><span class="p">:</span> <span class="n">fcr_bbox</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">min</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">max</span><span class="sh">"</span><span class="p">:</span> <span class="mi">30000</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="n">fcr_response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">fcr_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">fcr_PIL</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">fcr_response</span><span class="p">.</span><span class="n">raw</span><span class="p">)</span>

    <span class="n">fcr_PIL</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">fcr_images/fcr_</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="mi">03</span><span class="si">}</span><span class="s">.png</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div> </div> <p>With the images are combined into mp4 using <a href="https://en.wikipedia.org/wiki/FFmpeg">ffmpeg</a>.</p> </details> <p><br/></p> <figure> <video width="480" height="360" controls=""> <source src="/assets/img/blogs/Google_Earth_Engine/fiery_cross_reef_timelapse.mp4" type="video/mp4"/> </video> <figcaption>Timelapse of Fiery Cross Reef Terraforming</figcaption> </figure>]]></content><author><name></name></author><category term="Intros"/><category term="Remote-Sensing"/><category term="Data-Science"/><summary type="html"><![CDATA[Using Google's Earth Engine python library to query Sentinel-2 imagery]]></summary></entry><entry><title type="html">Diffusing Digits</title><link href="https://seanhoward.me/blog/2022/Diffusing_Digits/" rel="alternate" type="text/html" title="Diffusing Digits"/><published>2022-09-18T16:40:16+00:00</published><updated>2022-09-18T16:40:16+00:00</updated><id>https://seanhoward.me/blog/2022/Diffusing_Digits</id><content type="html" xml:base="https://seanhoward.me/blog/2022/Diffusing_Digits/"><![CDATA[<h1 id="diffusing-digits---generating-mnist-digits-from-noise-with-huggingface-diffusers">Diffusing Digits - Generating MNIST Digits from noise with HuggingFace Diffusers</h1> <p><a href="https://colab.research.google.com/github/st-howard/blog-notebooks/blob/main/MNIST-Diffusion/Diffusion%20Digits%20-%20Generating%20MNIST%20Digits%20from%20noise%20with%20HuggingFace%20Diffusers.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab"/></a></p> <figure> <video width="480" height="360" controls=""> <source src="/assets/img/blogs/Diffusing_Digits_files/diffusion.mp4" type="video/mp4"/> </video> <figcaption>Generating MNIST digits with diffusion</figcaption> </figure> <p>Diffusion models have become the state of the art generative model by learning how to progressively remove “noise” from a randomly generated noise field until the sample matches the training data distribution. Diffusion models are a fundamental part of several noteworthy text to image models, including Imagen, DALLE-2, and Stable Diffusion. However, they are capabilities beyond text to image generation and are applicable to a large variety of generative tasks.</p> <p>Here a minimal diffusion model is trained on the iconic <a href="http://yann.lecun.com/exdb/mnist/">MNIST Digits</a> database using several <a href="https://huggingface.co/">HuggingFace</a> libraries. The flow follows that of the <a href="https://github.com/huggingface/diffusers/blob/main/docs/source/training/overview.mdx">example</a> HuggingFace notebook for unconditional image generation. I chose HuggingFace libraries for the implementation to learn their framework and I found that they were a nice balance between coding everything up in raw PyTorch (as was done in <a href="https://huggingface.co/blog/annotated-diffusion">HuggingFace annotated diffusion blog post</a>) and tailored implementations such as Phil Wang’s <a href="https://github.com/lucidrains/denoising-diffusion-pytorch">denoising-diffusion-pytorch</a>.</p> <details> <summary> Diffusion Models - Quick Explanation </summary> <p>Conceptually, diffusion models are built upon a series of noising and denoising steps. In the noising process, random Gaussian noise is iteratively added to data (typically an image but can be any numeric datatype). After many steps of adding noise, the original data becomes indistinguishable from Gaussian noise. This noising process is going from <strong>right to left</strong> in the below figure from the <a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models paper</a> (often referred to as DDPM). In practice, getting from the original data to the step \(t\) of the noising process can be done in one go based upon convenient properties of Gaussians.</p> <figure> <img src="https://huggingface.co/blog/assets/78_annotated-diffusion/diffusion_figure.png" width="90%"/> </figure> <p>The real juice of diffusion models is the denoising process. In the figure above, each denoising step (<strong>left to right</strong> in above figure), attempts to remove the noise added from previous step. Given noisy data, the diffusion model tries to predict the noise present in the data (slightly different to the above depiction which shows the model learning the conditional probability distribution \(p(x_{t-1} \vert x_t)\)). This noise is iteratively removed until the denoised data, which by characteristic of the training distribution, is left.</p> <p>Diffusion models can be broken down into two algorithms, one for training and one for sampling.</p> <h3 id="diffusion-models---training">Diffusion Models - Training</h3> <p>The training algorithm is relatively simple and follow the steps</p> <ul> <li>Take data from training distribution</li> <li>Randomly select a step within the noisig/denoising process</li> <li>Sample random Gaussian noise with zero mean and unit variance</li> <li>Take noise field and data from training distribution and noise it to selected step from noising process.</li> <li>Predict the noise present in the noisy data</li> <li>Update model based upon mean squared error of actual noise and predicted noise</li> </ul> <p>Which is shown in the psuedocode from the <a href="https://arxiv.org/abs/2006.11239">Ho et. al paper</a>.</p> <figure> <img src="https://huggingface.co/blog/assets/78_annotated-diffusion/training.png" width="50%"/> <figcaption></figcaption> </figure> <h3 id="diffusion-models---sampling">Diffusion Models - Sampling</h3> <p>With a model that takes a noisy image and predicts the noise given the step in the noising chain, can iteratively denoise the data with the following steps</p> <ul> <li>Generate the fully noised data at last step \(T\)</li> <li>For each step in the chain, predict the noise in the image and remove some fraction of it.</li> </ul> <p>Which is shown in the pseudocode</p> <figure> <img src="https://huggingface.co/blog/assets/78_annotated-diffusion/sampling.png" width="50%"/> <figcaption></figcaption> </figure> <p>There are details about noise and learning rate schedules which were omitted from the above, but covered in the <a href="https://huggingface.co/blog/annotated-diffusion">annotated diffusion blog post</a></p> </details> <h2 id="outline">Outline</h2> <p>In creating a diffusion model with HuggingFace, I found there to be <strong>4</strong> main stages after choosing the hyperparameters, each with defined subtasks. I’ve shown an outline below</p> <ol> <li><a href="#defining-hyperparameters">Defining Hyperparameters</a> </li> <li><a href="#preparing-mnist-dataset">Preparing Dataset</a> <ul> <li><a href="#downloading-mnist-with-huggingface-datasets">Downloading MNIST with HuggingFace <code class="language-plaintext highlighter-rouge">datasets</code></a></li> <li><a href="#data-preprocessing-and-augmentation">Data preprocessing and augmentation</a></li> </ul> </li> <li><a href="#creating-the-diffusion-model">Creating the Diffusion Model</a> <ul> <li><a href="#u-net-for-mnist">U-Net for MNIST</a></li> <li><a href="#noise-scheduler">Noise Scheduler</a></li> <li><a href="#optimizer">Optimizer</a></li> <li><a href="#learning-rate-scheduler">Learning Rate Scheduler</a></li> </ul> </li> <li><a href="#training-the-model">Training the Model</a> <ul> <li><a href="#working-with-memory-restrictions">Working with memory restrictions</a></li> <li><a href="#creating-and-running-training-loop">Creating and running training script</a></li> </ul> </li> <li><a href="#sample-some-good-looking-digits">Sampling Images</a></li> </ol> <details> <summary> Import libraries </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pytorch
</span><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torchvision</span>

<span class="c1"># HuggingFace
</span><span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="n">diffusers</span>
<span class="kn">import</span> <span class="n">accelerate</span>

<span class="c1"># Training and Visualization
</span><span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">PIL</span>
</code></pre></div> </div> </details> <h2 id="defining-hyperparameters">Defining Hyperparameters</h2> <p>In the training config class shown below, I’ve chosen an image size of \(32 \times 32\) instead of the default MNIST resolution of \(28 \times 28\). This slight upscaling is in order to make the image width/height be a power of 2, i.e. \(2^5\). In the default U-Net architecture, each downsampling layer reduces the width and height of the image by 2. Therefore after the three downsampling blocks I used in the U-Net, the output size will be \(4 \times 4 \times N\), where \(N\) is a configurable parameter of the model architecture. As the width and height of the image is reduced, the number of learned channels increases. So in the U-Net configured here, the bottleneck layer has dimension of \(4 \times 4 \times 512\).</p> <p>The batch sizes chosen are done in order to comfortably fit on a 8 GB memory GPU. I find that training occupies approximately 4 GB of memory. Since one epoch contains all sixty thousand training examples, only a couple epochs are needed for the model to converge, with most of the learning being done within the first epoch.</p> <p>The <code class="language-plaintext highlighter-rouge">lr_warmup_steps</code> is the number of mini-batches where the learning rate is increased until hitting the base learning rate listed in <code class="language-plaintext highlighter-rouge">learning_rate</code>. After the learning rate reaches this value, a cosine scheduler is used to slowly decrease the learning rate, as described in <a href="https://arxiv.org/abs/2102.09672">Improved Denoising Diffusion Probabilistic Models</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TrainingConfig</span><span class="p">:</span>
    <span class="n">image_size</span><span class="o">=</span><span class="mi">32</span> <span class="c1">#Resize the digits to be a power of two
</span>    <span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">eval_batch_size</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">lr_warmpup_steps</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">mixed_precision</span> <span class="o">=</span> <span class="sh">'</span><span class="s">fp16</span><span class="sh">'</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
    
<span class="n">config</span> <span class="o">=</span> <span class="nc">TrainingConfig</span><span class="p">()</span>
</code></pre></div></div> <h2 id="preparing-mnist-dataset">Preparing MNIST Dataset</h2> <h3 id="downloading-mnist-with-huggingface-datasets">Downloading MNIST with HuggingFace <code class="language-plaintext highlighter-rouge">datasets</code></h3> <p>HuggingFace has almost ten thousand dataset for download, which can be searched from the <a href="https://huggingface.co/datasets">datasets tab</a> of their website. They can be downloaded with their <code class="language-plaintext highlighter-rouge">datasets</code> python library and the <a href="https://huggingface.co/docs/datasets/loading"><code class="language-plaintext highlighter-rouge">load_dataset()</code></a> function.</p> <p>If not specified, the data will be downloaded to the <code class="language-plaintext highlighter-rouge">~/.cache</code> directory. If you want to put the files in another location, either specify the <code class="language-plaintext highlighter-rouge">data_dir</code> optional argument or change the environment variable <code class="language-plaintext highlighter-rouge">HF_DATASETS_CACHE</code> to the desired path.</p> <p>Here MNIST digits are loaded into a <code class="language-plaintext highlighter-rouge">Dataset</code> object, where metadata, labels, and images can be accessed in a manner similar to python dictionaries.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="nf">load_dataset</span><span class="p">(</span><span class="sh">'</span><span class="s">mnist</span><span class="sh">'</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>The dataset object is conveniently accessible with methods similar to a python dictionary</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mnist_dataset</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Dataset({
    features: ['image', 'label'],
    num_rows: 60000
})
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mnist_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">"</span><span class="s">image</span><span class="sh">"</span><span class="p">].</span><span class="nf">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)).</span><span class="nf">show</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Image Size:</span><span class="sh">"</span><span class="p">,</span> <span class="n">mnist_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">"</span><span class="s">image</span><span class="sh">"</span><span class="p">].</span><span class="n">size</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Digit is labelled:</span><span class="sh">"</span><span class="p">,</span> <span class="n">mnist_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Diffusing_Digits_files/Diffusion_Digits_0.png" width="15%"/> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Image Size: (28, 28)
Digit is labelled: 5
</code></pre></div></div> <h3 id="data-preprocessing-and-augmentation">Data Preprocessing and Augmentation</h3> <p>As downloaded, the MNIST dataset contains 60,000 PIL images with pixel values in the range of \([0,255]\). The data must be scaled, resized, and turned into a tensor for ingestion by a PyTorch model. These transformations can be handled by torchvision’s transforms library. Transform objects can be sequentially listed in a Compose constructor, which will apply then apply the transformations when an image is passed as an argument.</p> <p>Three transforms are used. The first transforms the image to 32x32, in order to for the image width/height to be a power of two. The second transform turns the PIL image to a PyTorch tensor. When converting to a PyTorch tensor, the pixel range is transformed from \([0,255]\) to \([0,1]\). However, for the diffusion model the required pixel value range needs to be \([-1,1]\) since the Gaussian noise is zero mean, unit variance. Therefore, a lambda function is used to define a transform from \([0,1]\) to \([-1,1]\).</p> <p>The <code class="language-plaintext highlighter-rouge">Datasets</code> object has a method <code class="language-plaintext highlighter-rouge">set_transform()</code> which applies a function which takes the dataset object as an argument. Here the method is used to apply the torchvision transforms to the MNIST dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">preprocess</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Resize</span><span class="p">(</span>
                <span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">image_size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">image_size</span><span class="p">)),</span>
            <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
            <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)),</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="nf">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">"</span><span class="s">image</span><span class="sh">"</span><span class="p">]]</span>
    <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">images</span><span class="sh">"</span><span class="p">:</span> <span class="n">images</span><span class="p">}</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mnist_dataset</span><span class="p">.</span><span class="nf">reset_format</span><span class="p">()</span>
<span class="n">mnist_dataset</span><span class="p">.</span><span class="nf">set_transform</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
</code></pre></div></div> <p>Once the dataset has been prepared with the proper transformers, it is ready to be passed directly into a PyTorch DataLoader.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
    <span class="n">mnist_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">train_batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div> <h2 id="creating-the-diffusion-model">Creating the Diffusion Model</h2> <h3 id="u-net-for-mnist">U-Net for MNIST</h3> <p>The workhorse of the denoising diffusion model is a U-Net, which is predicts the noise present in the input image conditioned on the step in the noising process. HuggingFace’s Diffusers library has default a <a href="https://huggingface.co/docs/diffusers/api/models#diffusers.UNet2DModel">U-Net class</a> which creates a PyTorch model based upon the input values. Here the input and output channels are set to one since the image is black and white. The rest of the parameters mirror the choices found in the example notebook from HuggingFace.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">diffusers</span><span class="p">.</span><span class="nc">UNet2DModel</span><span class="p">(</span>
    <span class="n">sample_size</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">image_size</span><span class="p">,</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">layers_per_block</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">block_out_channels</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">512</span><span class="p">),</span>
    <span class="n">down_block_types</span><span class="o">=</span><span class="p">(</span>
        <span class="sh">"</span><span class="s">DownBlock2D</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">DownBlock2D</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">AttnDownBlock2D</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">DownBlock2D</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">up_block_types</span><span class="o">=</span><span class="p">(</span>
        <span class="sh">"</span><span class="s">UpBlock2D</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">AttnUpBlock2D</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">UpBlock2D</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">UpBlock2D</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>
</code></pre></div></div> <p>Check that the input image to the model and the output have the same shape</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_image</span> <span class="o">=</span> <span class="n">mnist_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">"</span><span class="s">images</span><span class="sh">"</span><span class="p">].</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Input shape:</span><span class="sh">"</span><span class="p">,</span> <span class="n">sample_image</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input shape: torch.Size([1, 1, 32, 32])
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Output shape:</span><span class="sh">'</span><span class="p">,</span> <span class="nf">model</span><span class="p">(</span><span class="n">sample_image</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="sh">"</span><span class="s">sample</span><span class="sh">"</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output shape: torch.Size([1, 1, 32, 32])
</code></pre></div></div> <h3 id="noise-scheduler">Noise Scheduler</h3> <p>In diffusion models, the noise is added to images dependent on the step within noising/denoising process. In the original <a href="https://arxiv.org/abs/2006.11239">DDPM paper</a>, the strength of the noise added to the image (i.e. the variance of the zero mean Gaussian) increased linearly with time steps. The Diffusers library has a <a href="https://huggingface.co/docs/diffusers/v0.3.0/en/api/schedulers#diffusers.DDPMScheduler">noise scheduler object</a> which handles the amount of noise to be added for a given step. The default values for noise are taken from the DDPM paper, but there are optional arguments to change the starting and ending noise strength, along with the how the noise changes with across steps.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">noise_scheduler</span> <span class="o">=</span> <span class="n">diffusers</span><span class="p">.</span><span class="nc">DDPMScheduler</span><span class="p">(</span><span class="n">num_train_timesteps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">tensor_format</span><span class="o">=</span><span class="sh">'</span><span class="s">pt</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>We can take a digit and use the scheduler object to add noise. Below is the</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original Digit</span><span class="sh">"</span><span class="p">)</span>
<span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToPILImage</span><span class="p">()(</span><span class="n">sample_image</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)).</span><span class="nf">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Original Digit
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Diffusing_Digits_files/Diffusion_Digits_1.png" width="15%"/> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">sample_image</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">LongTensor</span><span class="p">([</span><span class="mi">199</span><span class="p">])</span>
<span class="n">noisy_image</span> <span class="o">=</span> <span class="n">noise_scheduler</span><span class="p">.</span><span class="nf">add_noise</span><span class="p">(</span><span class="n">sample_image</span><span class="p">,</span><span class="n">noise</span><span class="p">,</span><span class="n">timesteps</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Fully Noised Digit</span><span class="sh">"</span><span class="p">)</span>
<span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToPILImage</span><span class="p">()(</span><span class="n">noisy_image</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)).</span><span class="nf">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fully Noised Digit
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Diffusing_Digits_files/Diffusion_Digits_2.png" width="15%"/> </figure> <h3 id="optimizer">Optimizer</h3> <p>Let’s have the U-Net can learn with the <a href="https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html">AdamW optimizer</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span><span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">)</span>
</code></pre></div></div> <h3 id="learning-rate-scheduler">Learning Rate Scheduler</h3> <p>As mentioned previously, in <a href="https://arxiv.org/abs/2102.09672">Improved Denoising Diffusion Probabilistic Models</a>, they find a learning rate schedule which first warmups for a fixed number of steps and then follows a cosine schedule thereafter to be effective in training the model. The diffusers library has a <a href="https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.get_cosine_schedule_with_warmup">method</a> which creates a PyTorch learning rate scheduler which follows the advice given in this paper.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Cosine learning rate scheduler
</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">diffusers</span><span class="p">.</span><span class="n">optimization</span><span class="p">.</span><span class="nf">get_cosine_schedule_with_warmup</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">lr_warmpup_steps</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span><span class="o">*</span><span class="n">config</span><span class="p">.</span><span class="n">num_epochs</span><span class="p">),</span>
<span class="p">)</span>
</code></pre></div></div> <h2 id="training-the-model">Training the Model</h2> <h3 id="working-with-memory-restrictions">Working with memory restrictions</h3> <p>Running this on my local machine, I found that unless I set a limit on the VRAM accessible to PyTorch it would use it all up. This is good for maximizing utilization of a GPU cluster, but bad when iterating on a machine where the same GPU is rendering the operating system.</p> <p>To get around this, there is a useful <a href="https://pytorch.org/docs/stable/generated/torch.cuda.set_per_process_memory_fraction.html">cuda function</a> within PyTorch which sets the maximum fraction of total memory accessible. I’ve set this to use 7 GB out of 8 GB, just so computer doesn’t come to a standstill.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">set_per_process_memory_fraction</span><span class="p">(</span><span class="mf">7.</span><span class="o">/</span><span class="mf">8.</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h3 id="creating-and-running-training-loop">Creating and Running Training Loop</h3> <p>The training function first creates a HuggingFace <a href="https://huggingface.co/docs/accelerate/v0.12.0/en/package_reference/accelerator#accelerator"><code class="language-plaintext highlighter-rouge">accelerator</code></a> object. The purpose of the <code class="language-plaintext highlighter-rouge">accelerator</code> object is to automatically handle device assignment for PyTorch objects when training on multiple devices and to make the code portable when running in multiple setups. Once created, the <code class="language-plaintext highlighter-rouge">accelerator</code> has a method <code class="language-plaintext highlighter-rouge">prepare</code> which takes all of the model/U-Net, optimizer, dataloader, and learning rate scheduler and automatically detects the correct device(s) and makes the appropriate <code class="language-plaintext highlighter-rouge">.to()</code> assignments.</p> <p>After those objects are “prepared”, the training has an outer <code class="language-plaintext highlighter-rouge">for</code> loop for each epoch and an inner <code class="language-plaintext highlighter-rouge">for</code> loop for each mini-batch. In each mini-batch, a set of digits is taken from the dataset. Random noise with the same size of the minibatch is then sampled. Then, for each image in the minibatch, a random step in the noising process is (uniformly) selected. Noise is then added to each image based upon the randomly sampled noise and the randomly selected step. The U-Net then predicts the noise added to the image conditioned on the selected step. A mean squared error loss is then calculated between the predicted noise and the actual noise added to the image. This loss is then used to update the weights for each mini-batch.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span>
        <span class="n">config</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">noise_scheduler</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">train_dataloader</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="p">):</span>

    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">accelerate</span><span class="p">.</span><span class="nc">Accelerator</span><span class="p">(</span>
        <span class="n">mixed_precision</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">mixed_precision</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">lr_scheduler</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
                            <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="p">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
            <span class="n">clean_images</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">images</span><span class="sh">'</span><span class="p">]</span>

            <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">clean_images</span><span class="p">.</span><span class="n">shape</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">clean_images</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">clean_images</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># Sample a set of random time steps for each image in mini-batch
</span>            <span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span> <span class="n">noise_scheduler</span><span class="p">.</span><span class="n">num_train_timesteps</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">clean_images</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            
            <span class="n">noisy_images</span><span class="o">=</span><span class="n">noise_scheduler</span><span class="p">.</span><span class="nf">add_noise</span><span class="p">(</span><span class="n">clean_images</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
            
            <span class="k">with</span> <span class="n">accelerator</span><span class="p">.</span><span class="nf">accumulate</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
                <span class="n">noise_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">noisy_images</span><span class="p">,</span><span class="n">timesteps</span><span class="p">)[</span><span class="sh">"</span><span class="s">sample</span><span class="sh">"</span><span class="p">]</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">noise_pred</span><span class="p">,</span><span class="n">noise</span><span class="p">)</span>
                <span class="n">accelerator</span><span class="p">.</span><span class="nf">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                
                <span class="n">accelerator</span><span class="p">.</span><span class="nf">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span><span class="mf">1.0</span><span class="p">)</span>
                <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
                <span class="n">lr_scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
                
            <span class="n">progress_bar</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">logs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sh">"</span><span class="s">loss</span><span class="sh">"</span> <span class="p">:</span> <span class="n">loss</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">item</span><span class="p">(),</span>
                <span class="sh">"</span><span class="s">lr</span><span class="sh">"</span> <span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">.</span><span class="nf">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">}</span>
            <span class="n">progress_bar</span><span class="p">.</span><span class="nf">set_postfix</span><span class="p">(</span><span class="o">**</span><span class="n">logs</span><span class="p">)</span>
    
    <span class="n">accelerator</span><span class="p">.</span><span class="nf">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <p>Once the training loop set up, the function along with its arguments can be passed to the accelerate library’s <a href="https://huggingface.co/docs/accelerate/v0.12.0/en/basic_tutorials/notebook#using-the-notebooklauncher"><code class="language-plaintext highlighter-rouge">notebook launcher</code></a> to train within the notebook.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">noise_scheduler</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">)</span>

<span class="n">accelerate</span><span class="p">.</span><span class="nf">notebook_launcher</span><span class="p">(</span><span class="n">train_loop</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <h2 id="create-a-sampling-function">Create a sampling function</h2> <p>Once the model has been trained, we can sample the model to create digits. Or more accurately create a sample which is within the learned distribution of the training samples, since some generated samples look like an alien’s numbering system, a mish-mash of the numbers 0-9.</p> <p>To sample images, the Diffusers library has several pipelines. However, <a href="https://github.com/huggingface/diffusers/issues/488">I found that these pipelines don’t work for single channel images</a> (<a href="https://github.com/huggingface/diffusers/pull/1025">which is now fixed!</a>). So I created a small function which samples the images, with an optional argument for saving off each step. Importantly, the function needs to have a <code class="language-plaintext highlighter-rouge">torch.no_grad()</code> decorator so the model doesn’t accumulate the history of the forward passes.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">unet</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span><span class="n">seed</span><span class="p">,</span><span class="n">save_process_dir</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">save_process_dir</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">save_process_dir</span><span class="p">):</span>
            <span class="n">os</span><span class="p">.</span><span class="nf">mkdir</span><span class="p">(</span><span class="n">save_process_dir</span><span class="p">)</span>
    
    <span class="n">scheduler</span><span class="p">.</span><span class="nf">set_timesteps</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">image</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">num_steps</span><span class="o">=</span><span class="nf">max</span><span class="p">(</span><span class="n">noise_scheduler</span><span class="p">.</span><span class="n">timesteps</span><span class="p">).</span><span class="nf">numpy</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">noise_scheduler</span><span class="p">.</span><span class="n">timesteps</span><span class="p">:</span>
        <span class="n">model_output</span><span class="o">=</span><span class="nf">unet</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">t</span><span class="p">)[</span><span class="sh">'</span><span class="s">sample</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">image</span><span class="o">=</span><span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">model_output</span><span class="p">,</span><span class="nf">int</span><span class="p">(</span><span class="n">t</span><span class="p">),</span><span class="n">image</span><span class="p">,</span><span class="n">generator</span><span class="o">=</span><span class="bp">None</span><span class="p">)[</span><span class="sh">'</span><span class="s">prev_sample</span><span class="sh">'</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">save_process_dir</span><span class="p">:</span>
            <span class="n">save_image</span><span class="o">=</span><span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToPILImage</span><span class="p">()(</span><span class="n">image</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
            <span class="n">save_image</span><span class="p">.</span><span class="nf">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">)).</span><span class="nf">save</span><span class="p">(</span>
                <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">save_process_dir</span><span class="p">,</span><span class="sh">"</span><span class="s">seed-</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span><span class="o">+</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="o">+</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">num_steps</span><span class="o">-</span><span class="n">t</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="sh">"</span><span class="o">+</span><span class="sh">"</span><span class="s">.png</span><span class="sh">"</span><span class="p">),</span><span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">png</span><span class="sh">"</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToPILImage</span><span class="p">()(</span><span class="n">image</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></div> <h2 id="sample-some-good-looking-digits">Sample some good looking digits!</h2> <p>Some samples look quit good…</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_image</span><span class="o">=</span><span class="nf">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">noise_scheduler</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">test_image</span><span class="p">.</span><span class="nf">resize</span><span class="p">((</span><span class="mi">265</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Diffusing_Digits_files/Diffusion_Digits_3.png" width="15%"/> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_image</span><span class="o">=</span><span class="nf">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">noise_scheduler</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">test_image</span><span class="p">.</span><span class="nf">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Diffusing_Digits_files/Diffusion_Digits_4.png" width="15%"/> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_image</span><span class="o">=</span><span class="nf">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">noise_scheduler</span><span class="p">,</span><span class="mi">1991</span><span class="p">)</span>
<span class="n">test_image</span><span class="p">.</span><span class="nf">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Diffusing_Digits_files/Diffusion_Digits_5.png" width="15%"/> </figure> <p>But others aren’t quite recognizable as a number, but look like they <em>could</em> be number if history went slightly differently…</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_image</span><span class="o">=</span><span class="nf">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">noise_scheduler</span><span class="p">,</span><span class="mi">2022</span><span class="p">)</span>
<span class="n">test_image</span><span class="p">.</span><span class="nf">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Diffusing_Digits_files/Diffusion_Digits_6.png" width="15%"/> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_image</span><span class="o">=</span><span class="nf">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">noise_scheduler</span><span class="p">,</span><span class="mi">42</span><span class="p">)</span>
<span class="n">test_image</span><span class="p">.</span><span class="nf">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
</code></pre></div></div> <figure> <img src="/assets/img/blogs/Diffusing_Digits_files/Diffusion_Digits_7.png" width="15%"/> </figure>]]></content><author><name></name></author><category term="Intros"/><category term="PyTorch"/><category term="Deep-Learning"/><category term="Diffusion"/><summary type="html"><![CDATA[Generating MNIST Digits from noise with HuggingFace Diffusers]]></summary></entry><entry><title type="html">A ‘Hello World’ for PyTorch</title><link href="https://seanhoward.me/blog/2022/Hello_World_PyTorch/" rel="alternate" type="text/html" title="A ‘Hello World’ for PyTorch"/><published>2022-09-07T16:40:16+00:00</published><updated>2022-09-07T16:40:16+00:00</updated><id>https://seanhoward.me/blog/2022/Hello_World_PyTorch</id><content type="html" xml:base="https://seanhoward.me/blog/2022/Hello_World_PyTorch/"><![CDATA[<p><a href="https://colab.research.google.com/github/st-howard/blog-notebooks/blob/main/Hello_World_PyTorch/Hello_World_PyTorch.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab"/></a></p> <p>PyTorch is a powerful machine learning library and is <a href="https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/">becoming the dominant deep learning framework</a>. I want to learn how to use PyTorch, so in the spirit of “Hello World”-like programs, the first thing I wanted to do is create a small neural network and train it on an easy dataset. The <a href="https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html">PyTorch tutorial</a> creates a fully connected neural network to train on FashionMNIST, but I want something even simpler so when things go wrong I’ll know that I’ve made a mistake somewhere.</p> <p>For this experiment, I’ll create a network of a few fully connected layers to classify the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html">two moons dataset</a>. I’ve chosen this dataset because the data is easily visualized and the optimal decision boundary is both non-linear and obvious on inspection.</p> <details> <summary> Load Libraries </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load libraries
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>

<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</code></pre></div> </div> </details> <details> <summary> Check for GPU </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># check that GPU is recognized
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Does PyTorch recognize the GPU?</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">Yes</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">No</span><span class="sh">"</span><span class="p">)</span>
<span class="n">device</span><span class="o">=</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span>
</code></pre></div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Does PyTorch recognize the GPU? Yes
</code></pre></div> </div> </details> <h2 id="the-dataset-two-moons">The Dataset: Two Moons</h2> <p>The first step is to investigate the toy dataset. The two moons dataset has one adjustable parameter, <code class="language-plaintext highlighter-rouge">noise</code>, which determines the spread of both half-moons. I’ve set <code class="language-plaintext highlighter-rouge">noise=0.1</code> so there are some values from each class that are very close at one end of each half moon. Even with this noise, the data appears separable such that a converged network should reach near 100% accuracy.</p> <details open=""> <summary> Generate Two Moons Dataset</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generate the Two Moons dataset
</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span> <span class="o">=</span> <span class="nf">make_moons</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</code></pre></div> </div> </details> <details> <summary> Plot Two Moons Dataset </summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot the Two Moons dataset
</span><span class="n">class_colors</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_data</span><span class="p">))):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span>
        <span class="n">x_data</span><span class="p">[</span><span class="n">y_data</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">x_data</span><span class="p">[</span><span class="n">y_data</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="n">class_colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Class </span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Two Moons Dataset</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div> </div> </details> <figure> <img src="/assets/img/blogs/Hello_World_PyTorch_files/two_moons.png" width="90%"/> <figcaption>The Two Moons toy dataset.</figcaption> </figure> <h2 id="construct-pytorch-model-and-dataset-for-training">Construct PyTorch Model and Dataset For Training</h2> <h3 id="make-network">Make Network</h3> <p>The simplest way to construct a neural network in PyTorch is with the <a href="https://pytorch.org/docs/master/generated/torch.nn.Sequential.html#torch.nn.Sequential">Sequential</a> container and <code class="language-plaintext highlighter-rouge">torch.nn</code> modules. This is one of <a href="https://h1ros.github.io/posts/3-ways-of-creating-a-neural-network-in-pytorch/">three ways</a> to construct a neural network in PyTorch. The network graph is defined by the order of the modules passed into <code class="language-plaintext highlighter-rouge">nn.Sequential</code>.</p> <p>The below model takes in the x and y values of two moons data set then has three fully connected hidden layers, with 20, 20, and 20 nodes respectively. A <a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html">ReLU</a> activation is used, followed by a <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">one dimensional batch normalization</a>. The final output could either be a <a href="https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/">one-hot encoding</a> or a logistic regression to value where values greater than 0.5 are classified as 1 and values less than 0.5 are classified as 0 . I’ve chosen the logistic regression option.</p> <details open=""> <summary>Define PyTorch Network in Sequential Container</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define a neural network
</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Number of trainable parameters:</span><span class="sh">"</span><span class="p">,</span> <span class="nf">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span>
      <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">))</span>
</code></pre></div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Sequential(
  (0): Linear(in_features=2, out_features=20, bias=True)
  (1): ReLU()
  (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): Linear(in_features=20, out_features=20, bias=True)
  (4): ReLU()
  (5): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (6): Linear(in_features=20, out_features=20, bias=True)
  (7): ReLU()
  (8): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (9): Linear(in_features=20, out_features=1, bias=True)
  (10): Sigmoid()
)
Number of trainable parameters: 1041
</code></pre></div> </div> </details> <h3 id="create-dataset-and-dataloader">Create Dataset and DataLoader</h3> <p>Next extend the <code class="language-plaintext highlighter-rouge">Dataset</code> class for the two moons dataset and create a <code class="language-plaintext highlighter-rouge">DataLoader</code> object. The extension of <code class="language-plaintext highlighter-rouge">Dataset</code> class must define a <code class="language-plaintext highlighter-rouge">__len__</code> function which returns the number of samples and a <code class="language-plaintext highlighter-rouge">__getitem__</code> function which returns an instance given an index. The <code class="language-plaintext highlighter-rouge">DataLoader</code> is a utility for iterating over the dataset. I’ve defined the minibatch size as 100, which is 10% of the 1000 instances of the two moons dataset. An enumerated <code class="language-plaintext highlighter-rouge">DataLoader</code> will provide one batch per iteration.</p> <details open=""> <summary>Create Dataset and DataLoader</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TwoMoons</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">x_data</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">y_data</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">Y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">Y</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create the training data as a DataLoader Object
</span><span class="n">two_moons</span> <span class="o">=</span> <span class="nc">TwoMoons</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">two_moons</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div> </div> </details> <h3 id="define-objective-function-and-optimizer">Define Objective Function and Optimizer</h3> <p>To train a network, a loss/objective function needs to be defined. This is the mathematical function which the network is trying to minimize. Since the above network is a regression problem, a mean squared error loss <code class="language-plaintext highlighter-rouge">MSELoss()</code> is an appropriate choice. This loss is minimized by the optimization algorithm, which takes the current predictions of the network and updates the model parameters. PyTorch has <a href="https://pytorch.org/docs/stable/optim.html">many optimization algorithms</a>, but I’ve used stochastic gradient descent or <a href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD"><code class="language-plaintext highlighter-rouge">SGD</code></a>.</p> <details open=""> <summary>Define Loss Function and Optimizer</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define Loss Function and Optimizer
</span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</code></pre></div> </div> </details> <h3 id="weight-initialization">Weight Initialization</h3> <p>Parameters in the network are initialized with reasonable defaults determined by PyTorch. For example, the <code class="language-plaintext highlighter-rouge">nn.Linear</code> module’s parameters are <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">initialized</a> from a uniform distribution (-$\sqrt{k}$,$\sqrt{k}$), where $k$ is the inverse of the number of input features to the layer. When training a network, the trainable parameters will change as the network learns. I found it helpful to be able to reset all the weights when experimenting, especially in combination with setting the default random seed. Resetting the network weights can be achieved by the <code class="language-plaintext highlighter-rouge">reset_parameters()</code> method for trainable modules (in this case the <code class="language-plaintext highlighter-rouge">nn.Linear</code> and <code class="language-plaintext highlighter-rouge">nn.BatchNorm1d</code> layers). By using the apply method of the <code class="language-plaintext highlighter-rouge">Sequential</code> container, the weights of each layer can be reset with below function:</p> <details open=""> <summary>Create helper function for resetting weights</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">reset_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">or</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm1d</span><span class="p">):</span>
            <span class="n">m</span><span class="p">.</span><span class="nf">reset_parameters</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">reset_weights</span><span class="p">)</span>
</code></pre></div> </div> </details> <h2 id="train-the-model">Train the Model</h2> <p>With a network, loss function, optimization method, and a way to handle the data, we can begin to train the network. This is divided into two main steps, initialization and training.</p> <ol> <li>Initialization <ul> <li><strong>Determine how long to train.</strong> In this case, I train for 10 epochs. Alternatively could train until certain loss is achieved. An epoch is a full pass through the training data. Based upon how I set up the <code class="language-plaintext highlighter-rouge">DataLoader</code>, one epoch consists of 10 mini-batches. In each mini-batch, a noisy estimate of the loss (noisy since only calculated on a fraction of the training data) is calculated and used to update the model weights. Many machine learning tasks are non-convex optimization problems, <a href="https://datascience.stackexchange.com/questions/16807/why-mini-batch-size-is-better-than-one-single-batch-with-all-training-data">where a noisy estimate of the loss often outperforms the true loss</a> since it can escape local minima in the loss function.</li> <li><strong>Set the random seed.</strong> When things go wrong, it is helpful to remove the RNG from what is happening. Each random seed will give different initial weights to the network and therefore different initial accuracy+decision boundary.</li> <li><strong>Initial performance of Model.</strong> With weights initialized, test the accuracy of the model. On average expect this to be around 50% for binary classification, but will be off based on network architecture and initial weights.</li> </ul> </li> <li>Training <ul> <li><strong>Zero the gradients.</strong> By default the <a href="https://pytorch.org/tutorials/recipes/recipes/zeroing_out_gradients.html">gradients are accumulated in a buffer</a>, so need to zero them out so back propagation is calculated correctly.</li> <li><strong>Make prediction and calculate loss.</strong> Network output is calculated by passing the input values directly to the model object. These predictions and the true values are then passed to the loss function, giving the loss for the mini-batch.</li> <li><strong>Back Propagation.</strong> With a loss, we can calculate the gradient of the network with <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html"><code class="language-plaintext highlighter-rouge">.backward()</code></a>. After the gradient is calculated, the optimizer can update the weights of the network with the <a href="https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html"><code class="language-plaintext highlighter-rouge">.step()</code></a> method.</li> </ul> </li> </ol> <details open=""> <summary>Initialize and Train the Model</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 1. Initialization
</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="nf">init_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">loss_history</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_epochs</span><span class="p">))</span>
<span class="n">accuracy_history</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_epochs</span><span class="p">))</span>

<span class="n">initial_preds</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">two_moons</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="nf">float</span><span class="p">())</span>
<span class="n">initial_loss</span> <span class="o">=</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">initial_preds</span><span class="p">,</span> <span class="n">two_moons</span><span class="p">.</span><span class="n">Y</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">float</span><span class="p">())</span>
<span class="n">initial_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eq</span><span class="p">(</span><span class="n">initial_preds</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">).</span><span class="nf">round</span><span class="p">().</span><span class="nf">bool</span><span class="p">(),</span> <span class="n">two_moons</span><span class="p">.</span><span class="n">Y</span><span class="p">.</span><span class="nf">bool</span><span class="p">()).</span><span class="nf">sum</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Initial Loss: </span><span class="si">{</span><span class="n">initial_loss</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Initial Accuracy: </span><span class="si">{</span><span class="n">initial_acc</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">two_moons</span><span class="p">)</span><span class="si">}</span><span class="s"> </span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

<span class="c1">#2. Learning
</span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_samples</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_data</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="nf">float</span><span class="p">())</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">float</span><span class="p">())</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">num_correct</span> <span class="o">+=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eq</span><span class="p">(</span><span class="n">predictions</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">round</span><span class="p">().</span><span class="nf">bool</span><span class="p">(),</span>
                                <span class="n">targets</span><span class="p">.</span><span class="nf">bool</span><span class="p">()).</span><span class="nf">sum</span><span class="p">()</span>
        <span class="n">total_samples</span> <span class="o">+=</span> <span class="n">targets</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">loss_history</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">running_loss</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
    <span class="n">accuracy_history</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_correct</span><span class="o">/</span><span class="n">total_samples</span>

    <span class="nf">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="sh">"</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="mi">02</span><span class="n">d</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s"> | Loss: </span><span class="si">{</span><span class="n">loss_history</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">5</span><span class="n">f</span><span class="si">}</span><span class="s"> </span><span class="se">\t</span><span class="s"> | Accuracy: </span><span class="si">{</span><span class="n">accuracy_history</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">5</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Initial Loss: 0.25068870186805725
Initial Accuracy: 0.5560000538825989 

Epoch: 01/10 | Loss: 0.09092 	 | Accuracy: 0.88900
Epoch: 02/10 | Loss: 0.01654 	 | Accuracy: 0.98800
Epoch: 03/10 | Loss: 0.00792 	 | Accuracy: 0.99200
Epoch: 04/10 | Loss: 0.00350 	 | Accuracy: 0.99700
Epoch: 05/10 | Loss: 0.00244 	 | Accuracy: 0.99800
Epoch: 06/10 | Loss: 0.00178 	 | Accuracy: 0.99800
Epoch: 07/10 | Loss: 0.00155 	 | Accuracy: 1.00000
Epoch: 08/10 | Loss: 0.00136 	 | Accuracy: 0.99900
Epoch: 09/10 | Loss: 0.00119 	 | Accuracy: 1.00000
Epoch: 10/10 | Loss: 0.00133 	 | Accuracy: 0.99800
</code></pre></div> </div> </details> <h2 id="inspect-model-results">Inspect Model Results</h2> <p>In addition to training, I’ve kept track of the model accuracy (correct predictions) and the model loss (mean squared error) across each epoch. The network converges to an optimal solution very quickly, reaching 98.8% accuracy after just two epochs.</p> <details> <summary>Plot Loss and Accuracy Curves</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot the Loss History and the Accuracy
# Plot the Loss and Accuracy History
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">ax1</span><span class="p">.</span><span class="nf">twinx</span><span class="p">()</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">),</span> <span class="n">loss_history</span><span class="p">,</span> <span class="sh">'</span><span class="s">g-</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Loss</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">),</span> <span class="n">accuracy_history</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">b-</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Accuracy</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Epoch</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">MSE Loss</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Accuracy</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</code></pre></div> </div> </details> <figure> <img src="/assets/img/blogs/Hello_World_PyTorch_files/history.png" width="90%"/> <figcaption>Loss and Accuracy During Training</figcaption> </figure> <p>Additionally, by making predictions for a grid of points, we can visualize the decision boundary learned by the network. I’ve found that the decision boundary between regions where there is training data is similar across random seeds. However, the decision boundary outside of this distribution changes based on the random seed/initial state of the network. This highlights a (potential) weakness of neural nets, as <a href="https://ai.googleblog.com/2019/12/improving-out-of-distribution-detection.html">they can perform poorly on data out of their training distribution</a>.</p> <details> <summary>Plot Decision Boundary</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot the scatter plot and the decision boundary
</span>
<span class="n">x0_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">x1_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">pred_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">x0_grid</span><span class="p">,</span> <span class="n">x1_grid</span><span class="p">)))</span>
<span class="n">pred_grid</span> <span class="o">=</span> <span class="n">pred_grid</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span>
<span class="n">pred_array</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">pred_grid</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">pred_grid</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">pred_grid</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">makeGridPrediction</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">pred_array</span><span class="p">):</span>
    <span class="n">model_array_preds</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">pred_array</span><span class="p">.</span><span class="nf">float</span><span class="p">())</span>

    <span class="n">model_grid_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">flip</span><span class="p">(</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">model_array_preds</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="p">(</span><span class="n">pred_grid</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pred_grid</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="p">),</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">model_grid_preds</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>


<span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span>
    <span class="nf">makeGridPrediction</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">pred_array</span><span class="p">),</span>
    <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="n">x0_grid</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x0_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x1_grid</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x1_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
    <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">seismic_r</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Plot the data again
</span><span class="n">class_colors</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y_data</span><span class="p">))):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span>
        <span class="n">x_data</span><span class="p">[</span><span class="n">y_data</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">x_data</span><span class="p">[</span><span class="n">y_data</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="n">class_colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Class </span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Two Moons Dataset - Learned Decision Boundary</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div> </div> </details> <figure> <img src="/assets/img/blogs/Hello_World_PyTorch_files/boundary.png" width="90%"/> <figcaption>The learned decision boundary of network.</figcaption> </figure> <h4 id="check-network-evolution">Check Network Evolution</h4> <p>The evolution of the network can be visualized for this toy dataset by plotting the decision boundary for each mini-batch. Also, the impact of random weight initialization can be seen by the two different decision boundaries for the first mini-batch.</p> <figure> <video width="480" height="360" controls=""> <source src="/assets/img/blogs/Hello_World_PyTorch_files/learning_seed42.mp4" type="video/mp4"/> </video> <figcaption>Network Evolution - Random Seed = 42</figcaption> </figure> <figure> <video width="480" height="360" controls=""> <source src="/assets/img/blogs/Hello_World_PyTorch_files/learning_seed2022.mp4" type="video/mp4"/> </video> <figcaption>Network Evolution - Random Seed = 2022</figcaption> </figure>]]></content><author><name></name></author><category term="Intros"/><category term="PyTorch"/><category term="Deep-Learning"/><summary type="html"><![CDATA[A minimal neural network in PyTorch]]></summary></entry></feed>